<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.26">

  <title>JSC 370: Data Science II</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-0fde88a82f0356838740f155f1088782.css">
  <link rel="stylesheet" href="styles.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
  <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">JSC 370: Data Science II</h1>
  <p class="subtitle">Week 6: Text Mining &amp; Large Language Models</p>

<div class="quarto-title-authors">
</div>

</section>
<section id="what-is-nlp" class="slide level2">
<h2>What is NLP?</h2>
<p>Natural Language Processing (NLP) is used for <strong>qualitative data</strong> that is collected using:</p>
<ul>
<li>Open-ended or free-form text from surveys</li>
<li>Medical provider notes in electronic medical records (EMR)</li>
<li>Transcripts of research participant interviews</li>
<li>Social media posts, reviews, and other user-generated content</li>
</ul>
<p>It is also called <strong>text mining</strong>.</p>
</section>
<section id="what-is-nlp-used-for" class="slide level2">
<h2>What is NLP used for?</h2>
<ul>
<li>Looking at frequencies of words and phrases in text</li>
<li>Labeling relationships between words (subject, object, modification)</li>
<li>Identifying entities in free text (person, location, organization)</li>
<li>Coupled with AI/LLMs: text generation, summarization, classification, and more</li>
</ul>
</section>
<section id="python-nlp-ecosystem" class="slide level2">
<h2>Python NLP Ecosystem</h2>
<p><strong>Key Libraries:</strong></p>
<ul>
<li><strong>NLTK</strong>: Classic NLP toolkit with tokenizers, stemmers, taggers</li>
<li><strong>spaCy</strong>: NLP with pre-trained models</li>
<li><strong>scikit-learn</strong>: TF-IDF, topic modeling, text classification</li>
<li><strong>transformers (Hugging Face)</strong>: State-of-the-art LLMs</li>
<li><strong>gensim</strong>: Topic modeling and word embeddings</li>
</ul>
</section>
<section id="setup" class="slide level2">
<h2>Setup</h2>
<div id="490c4bae" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a></a><span class="im">import</span> nltk</span>
<span id="cb1-4"><a></a><span class="im">import</span> re</span>
<span id="cb1-5"><a></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-6"><a></a></span>
<span id="cb1-7"><a></a>nltk.download(<span class="st">'punkt'</span>, quiet<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-8"><a></a>nltk.download(<span class="st">'stopwords'</span>, quiet<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-9"><a></a>nltk.download(<span class="st">'vader_lexicon'</span>, quiet<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-10"><a></a>nltk.download(<span class="st">'punkt_tab'</span>, quiet<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-11"><a></a></span>
<span id="cb1-12"><a></a><span class="im">from</span> plotnine <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-13"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt  </span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="pride-and-prejudice" class="slide level2">
<h2>Pride and Prejudice</h2>
<p>We’ll use Jane Austen’s “Pride and Prejudice” from NLTK’s Gutenberg corpus.</p>
<div id="2c076f41" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a>nltk.download(<span class="st">'gutenberg'</span>, quiet<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-2"><a></a><span class="im">from</span> nltk.corpus <span class="im">import</span> gutenberg</span>
<span id="cb2-3"><a></a></span>
<span id="cb2-4"><a></a><span class="co"># Load Pride and Prejudice</span></span>
<span id="cb2-5"><a></a>raw_text <span class="op">=</span> gutenberg.raw(<span class="st">'austen-persuasion.txt'</span>)</span>
<span id="cb2-6"><a></a><span class="bu">print</span>(<span class="ss">f"Total characters: </span><span class="sc">{</span><span class="bu">len</span>(raw_text)<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb2-7"><a></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">First 500 characters:</span><span class="ch">\n</span><span class="sc">{</span>raw_text[:<span class="dv">500</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total characters: 466,292

First 500 characters:
[Persuasion by Jane Austen 1818]


Chapter 1


Sir Walter Elliot, of Kellynch Hall, in Somersetshire, was a man who,
for his own amusement, never took up any book but the Baronetage;
there he found occupation for an idle hour, and consolation in a
distressed one; there his faculties were roused into admiration and
respect, by contemplating the limited remnant of the earliest patents;
there any unwelcome sensations, arising from domestic affairs
changed naturally into pity and contempt as he turn</code></pre>
</div>
</div>
</section>
<section id="preparing-the-text-data" class="slide level2">
<h2>Preparing the Text Data</h2>
<ul>
<li>Split the text into chapters (Persuasion has chapters marked)</li>
<li>Create a DataFrame</li>
</ul>
<div id="caac0406" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a>chapters <span class="op">=</span> re.split(<span class="vs">r'Chapter </span><span class="dv">\d</span><span class="op">+</span><span class="vs">'</span>, raw_text)[<span class="dv">1</span>:]  <span class="co"># Skip preamble</span></span>
<span id="cb4-2"><a></a><span class="bu">print</span>(<span class="ss">f"Number of chapters: </span><span class="sc">{</span><span class="bu">len</span>(chapters)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-3"><a></a></span>
<span id="cb4-4"><a></a></span>
<span id="cb4-5"><a></a>text_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb4-6"><a></a>    <span class="st">'chapter'</span>: <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(chapters) <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb4-7"><a></a>    <span class="st">'text'</span>: [ch.strip() <span class="cf">for</span> ch <span class="kw">in</span> chapters]</span>
<span id="cb4-8"><a></a>})</span>
<span id="cb4-9"><a></a>text_df.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of chapters: 24</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="43">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">chapter</th>
<th data-quarto-table-cell-role="th">text</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>1</td>
<td>Sir Walter Elliot, of Kellynch Hall, in Somers...</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>2</td>
<td>Mr Shepherd, a civil, cautious lawyer, who, wh...</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>3</td>
<td>"I must take leave to observe, Sir Walter," sa...</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>4</td>
<td>He was not Mr Wentworth, the former curate of ...</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>5</td>
<td>On the morning appointed for Admiral and Mrs C...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="tokenization" class="slide level2">
<h2>Tokenization</h2>
<p>Turning text into smaller units (tokens): individual words, numbers, or punctuation marks.</p>
<p><strong>In English:</strong></p>
<ul>
<li>Split by spaces (simple approach)</li>
<li>More advanced algorithms handle contractions, punctuation</li>
</ul>
</section>
<section id="why-tokenize" class="slide level2 scrollable">
<h2>Why Tokenize?</h2>
<p>Tokenization is the <strong>first step</strong> in most NLP pipelines because:</p>
<ol type="1">
<li><strong>Computers don’t understand sentences</strong> - they need discrete units to process</li>
<li><strong>Enables counting</strong> - we can count word frequencies, find patterns</li>
<li><strong>Allows filtering</strong> - remove stop words, punctuation, or rare words</li>
<li><strong>Prepares for modeling</strong> - tokens become features for machine learning</li>
</ol>
</section>
<section id="tokenization-with-nltk" class="slide level2">
<h2>Tokenization with NLTK</h2>
<p>NLTK’s <code>word_tokenize()</code> uses the <strong>Punkt tokenizer</strong>, which is trained on text to recognize:</p>
<ul>
<li>Word boundaries (not just spaces)</li>
<li>Abbreviations (e.g., “Dr.”, “U.S.A.”)</li>
<li>Contractions (e.g., “don’t” → “do” + “n’t”)</li>
<li>Punctuation as separate tokens</li>
</ul>
<div id="97351a3b" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb6-2"><a></a></span>
<span id="cb6-3"><a></a>all_text <span class="op">=</span> <span class="st">' '</span>.join(text_df[<span class="st">'text'</span>])</span>
<span id="cb6-4"><a></a>tokens <span class="op">=</span> word_tokenize(all_text.lower())</span>
<span id="cb6-5"><a></a></span>
<span id="cb6-6"><a></a><span class="bu">print</span>(<span class="ss">f"Total tokens: </span><span class="sc">{</span><span class="bu">len</span>(tokens)<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb6-7"><a></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">First 20 tokens: </span><span class="sc">{</span>tokens[:<span class="dv">20</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total tokens: 97,884

First 20 tokens: ['sir', 'walter', 'elliot', ',', 'of', 'kellynch', 'hall', ',', 'in', 'somersetshire', ',', 'was', 'a', 'man', 'who', ',', 'for', 'his', 'own', 'amusement']</code></pre>
</div>
</div>
</section>
<section id="tokenization-what-happened" class="slide level2">
<h2>Tokenization: What Happened?</h2>
<p>Notice in the output:</p>
<ul>
<li><strong>Lowercase conversion</strong>: “The” becomes “the” (normalizes text)</li>
<li><strong>Punctuation separated</strong>: Periods, commas become their own tokens</li>
<li><strong>Contractions split</strong>: “didn’t” becomes “did” + “n’t”</li>
</ul>
<p>This gives us a <strong>clean list of tokens</strong> ready for analysis.</p>
</section>
<section id="spacy-industrial-strength-nlp" class="slide level2">
<h2>spaCy: “Industrial-Strength” NLP</h2>
<p><strong>spaCy</strong> is a modern NLP library designed for production use (https://spacy.io/). Unlike NLTK (which is more educational), spaCy focuses on:</p>
<ul>
<li><strong>Speed</strong>: Optimized for large-scale text processing</li>
<li><strong>Pre-trained models</strong>: Download models trained on large corpora</li>
<li><strong>Rich annotations</strong>: Tokenization + parts of speech (POS) tagging + named entity recognition (NER) + dependency parsing (relationships between words) in one pass</li>
</ul>
</section>
<section id="spacy-models" class="slide level2">
<h2>spaCy Models</h2>
<p>spaCy uses pre-trained <strong>language models</strong> that you download:</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Model</th>
<th>Size</th>
<th>Features</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>en_core_web_sm</code></td>
<td>12 MB</td>
<td>Basic (POS, NER, parsing)</td>
</tr>
<tr class="even">
<td><code>en_core_web_md</code></td>
<td>40 MB</td>
<td>+ word vectors</td>
</tr>
<tr class="odd">
<td><code>en_core_web_lg</code></td>
<td>560 MB</td>
<td>+ larger word vectors</td>
</tr>
</tbody>
</table>
<p>Install with: <code>python -m spacy download en_core_web_sm</code></p>
</section>
<section id="tokenization-with-spacy" class="slide level2">
<h2>Tokenization with spaCy</h2>
<p>When you call <code>nlp(text)</code>, spaCy creates a <code>Doc</code> object containing <code>Token</code> objects. Each token has many attributes:</p>
<ul>
<li><code>token.text</code> - the original text</li>
<li><code>token.pos_</code> - part-of-speech tag (NOUN, VERB, ADJ, etc.)</li>
<li><code>token.lemma_</code> - base form (“running” → “run”)</li>
<li><code>token.is_stop</code> - is it a stop word?</li>
</ul>
<div id="b36edc22" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a><span class="im">import</span> spacy</span>
<span id="cb8-2"><a></a></span>
<span id="cb8-3"><a></a><span class="co"># Load English model (small)</span></span>
<span id="cb8-4"><a></a>nlp <span class="op">=</span> spacy.load(<span class="st">"en_core_web_sm"</span>)</span>
<span id="cb8-5"><a></a></span>
<span id="cb8-6"><a></a></span>
<span id="cb8-7"><a></a><span class="co"># Process a sample</span></span>
<span id="cb8-8"><a></a>sample <span class="op">=</span> text_df[<span class="st">'text'</span>].iloc[<span class="dv">0</span>][:<span class="dv">500</span>]</span>
<span id="cb8-9"><a></a>doc <span class="op">=</span> nlp(sample)</span>
<span id="cb8-10"><a></a></span>
<span id="cb8-11"><a></a><span class="bu">print</span>(<span class="st">"SpaCy tokens with POS tags:"</span>)</span>
<span id="cb8-12"><a></a><span class="cf">for</span> token <span class="kw">in</span> <span class="bu">list</span>(doc)[:<span class="dv">15</span>]:</span>
<span id="cb8-13"><a></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>token<span class="sc">.</span>text<span class="sc">:15}</span><span class="ss"> -&gt; </span><span class="sc">{</span>token<span class="sc">.</span>pos_<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>SpaCy tokens with POS tags:
  Sir             -&gt; PROPN
  Walter          -&gt; PROPN
  Elliot          -&gt; PROPN
  ,               -&gt; PUNCT
  of              -&gt; ADP
  Kellynch        -&gt; PROPN
  Hall            -&gt; PROPN
  ,               -&gt; PUNCT
  in              -&gt; ADP
  Somersetshire   -&gt; PROPN
  ,               -&gt; PUNCT
  was             -&gt; AUX
  a               -&gt; DET
  man             -&gt; NOUN
  who             -&gt; PRON</code></pre>
</div>
</div>
</section>
<section id="understanding-pos-tags" class="slide level2">
<h2>Understanding POS Tags</h2>
<p><strong>Part-of-Speech (POS) tags</strong> identify the grammatical role of each word:</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Tag</th>
<th>Meaning</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>NOUN</code></td>
<td>Noun</td>
<td>cat, house, idea</td>
</tr>
<tr class="even">
<td><code>VERB</code></td>
<td>Verb</td>
<td>run, is, thinking</td>
</tr>
<tr class="odd">
<td><code>ADJ</code></td>
<td>Adjective</td>
<td>beautiful, quick</td>
</tr>
<tr class="even">
<td><code>ADV</code></td>
<td>Adverb</td>
<td>quickly, very</td>
</tr>
<tr class="odd">
<td><code>PROPN</code></td>
<td>Proper noun</td>
<td>Elizabeth, London</td>
</tr>
<tr class="even">
<td><code>PUNCT</code></td>
<td>Punctuation</td>
<td>. , ! ?</td>
</tr>
<tr class="odd">
<td><code>DET</code></td>
<td>Determiner</td>
<td>the, a, this</td>
</tr>
</tbody>
</table>
<p>POS tags help with tasks like finding all the <strong>people</strong> (PROPN) or <strong>actions</strong> (VERB) in text.</p>
</section>
<section id="named-entity-recognition-ner" class="slide level2">
<h2>Named Entity Recognition (NER)</h2>
<p><strong>NER</strong> identifies and classifies named entities in text into predefined categories:</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Entity Type</th>
<th>Description</th>
<th>Examples</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>PERSON</code></td>
<td>People’s names</td>
<td>Elizabeth Bennet, Mr.&nbsp;Darcy</td>
</tr>
<tr class="even">
<td><code>ORG</code></td>
<td>Organizations</td>
<td>Google, United Nations</td>
</tr>
<tr class="odd">
<td><code>GPE</code></td>
<td>Countries, cities, states</td>
<td>England, Toronto, California</td>
</tr>
<tr class="even">
<td><code>DATE</code></td>
<td>Dates and periods</td>
<td>January 2024, the 1800s</td>
</tr>
<tr class="odd">
<td><code>MONEY</code></td>
<td>Monetary values</td>
<td>$100, fifty dollars</td>
</tr>
<tr class="even">
<td><code>WORK_OF_ART</code></td>
<td>Titles of books, songs</td>
<td>Pride and Prejudice</td>
</tr>
</tbody>
</table>
</section>
<section id="ner-example-with-spacy" class="slide level2">
<h2>NER Example with spaCy</h2>
<ul>
<li>Let’s show it on a sample of text</li>
</ul>
<div id="18e8ff71" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a>sample_text <span class="op">=</span> <span class="st">"Elizabeth Bennet lived in Hertfordshire, England in the early 1800s."</span></span>
<span id="cb10-2"><a></a>doc <span class="op">=</span> nlp(sample_text)</span>
<span id="cb10-3"><a></a></span>
<span id="cb10-4"><a></a><span class="bu">print</span>(<span class="st">"Named Entities:"</span>)</span>
<span id="cb10-5"><a></a><span class="cf">for</span> ent <span class="kw">in</span> doc.ents:</span>
<span id="cb10-6"><a></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>ent<span class="sc">.</span>text<span class="sc">:20}</span><span class="ss"> -&gt; </span><span class="sc">{</span>ent<span class="sc">.</span>label_<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Named Entities:
  Elizabeth Bennet     -&gt; PERSON
  Hertfordshire        -&gt; GPE
  England              -&gt; GPE
  the early 1800s      -&gt; DATE</code></pre>
</div>
</div>
<p>NER is useful for:</p>
<ul>
<li><strong>Information extraction</strong>: Find all people/places mentioned</li>
<li><strong>Document classification</strong>: What topics does this text cover?</li>
<li><strong>Knowledge graphs</strong>: Build relationships between entities</li>
</ul>
</section>
<section id="dependency-parsing" class="slide level2">
<h2>Dependency Parsing</h2>
<p><strong>Dependency parsing</strong> analyzes the grammatical structure of a sentence by identifying relationships between words.</p>
<p>Each word is connected to a <strong>head</strong> word with a labeled relationship:</p>
<ul>
<li><code>nsubj</code> - nominal subject (“Elizabeth” is subject of “lived”)</li>
<li><code>dobj</code> - direct object (“book” in “I read the book”)</li>
<li><code>prep</code> - preposition (“in” connecting “lived” to “England”)</li>
<li><code>amod</code> - adjectival modifier (“red” in “red car”)</li>
</ul>
</section>
<section id="dependency-parsing-example" class="slide level2">
<h2>Dependency Parsing Example</h2>
<div id="4c119811" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a><span class="co"># Parse a simple sentence</span></span>
<span id="cb12-2"><a></a>sentence <span class="op">=</span> <span class="st">"Elizabeth gave the letter to Mr. Darcy."</span></span>
<span id="cb12-3"><a></a>doc <span class="op">=</span> nlp(sentence)</span>
<span id="cb12-4"><a></a></span>
<span id="cb12-5"><a></a><span class="bu">print</span>(<span class="st">"Dependency Parse:"</span>)</span>
<span id="cb12-6"><a></a><span class="cf">for</span> token <span class="kw">in</span> doc:</span>
<span id="cb12-7"><a></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>token<span class="sc">.</span>text<span class="sc">:12}</span><span class="ss"> --</span><span class="sc">{</span>token<span class="sc">.</span>dep_<span class="sc">:10}</span><span class="ss">--&gt; </span><span class="sc">{</span>token<span class="sc">.</span>head<span class="sc">.</span>text<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dependency Parse:
  Elizabeth    --nsubj     --&gt; gave
  gave         --ROOT      --&gt; gave
  the          --det       --&gt; letter
  letter       --dobj      --&gt; gave
  to           --dative    --&gt; gave
  Mr.          --compound  --&gt; Darcy
  Darcy        --pobj      --&gt; to
  .            --punct     --&gt; gave</code></pre>
</div>
</div>
</section>
<section id="why-dependency-parsing-matters" class="slide level2">
<h2>Why Dependency Parsing Matters</h2>
<p>Dependency parsing helps understand <strong>meaning</strong>, not just words:</p>
<ul>
<li><p><strong>“The dog bit the man”</strong> vs <strong>“The man bit the dog”</strong></p>
<ul>
<li>Same words, different subjects/objects!</li>
</ul></li>
<li><p><strong>Question answering</strong>: “Who gave the letter?” → Find the <code>nsubj</code> of “gave”</p></li>
<li><p><strong>Relation extraction</strong>: Understand who did what to whom</p></li>
<li><p><strong>Machine translation</strong>: Languages have different word orders</p></li>
</ul>
</section>
<section id="working-with-tokens-as-data" class="slide level2">
<h2>Working with Tokens as Data</h2>
<p>Now that we have words as the unit of observation, we can use pandas for analysis. First we create a dataframe from the tokens.</p>
<div id="523ffc39" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a>tokens_df <span class="op">=</span> pd.DataFrame({<span class="st">'token'</span>: tokens})</span>
<span id="cb14-2"><a></a><span class="bu">print</span>(<span class="ss">f"Shape: </span><span class="sc">{</span>tokens_df<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-3"><a></a>tokens_df.head(<span class="dv">10</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Shape: (97884, 1)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="48">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">token</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>sir</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>walter</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>elliot</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>,</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>of</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">5</th>
<td>kellynch</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">6</th>
<td>hall</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">7</th>
<td>,</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">8</th>
<td>in</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">9</th>
<td>somersetshire</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="counting-tokens" class="slide level2">
<h2>Counting Tokens</h2>
<div id="46456d87" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a><span class="co"># Count token frequencies</span></span>
<span id="cb16-2"><a></a>token_counts <span class="op">=</span> tokens_df[<span class="st">'token'</span>].value_counts().reset_index()</span>
<span id="cb16-3"><a></a>token_counts.columns <span class="op">=</span> [<span class="st">'token'</span>, <span class="st">'n'</span>]</span>
<span id="cb16-4"><a></a>token_counts.head(<span class="dv">15</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">token</th>
<th data-quarto-table-cell-role="th">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>,</td>
<td>7024</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>the</td>
<td>3328</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>.</td>
<td>3118</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>and</td>
<td>2786</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>to</td>
<td>2782</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">5</th>
<td>of</td>
<td>2568</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">6</th>
<td>a</td>
<td>1592</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">7</th>
<td>in</td>
<td>1383</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">8</th>
<td>was</td>
<td>1337</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">9</th>
<td>;</td>
<td>1319</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">10</th>
<td>her</td>
<td>1204</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">11</th>
<td>had</td>
<td>1186</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">12</th>
<td>she</td>
<td>1146</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">13</th>
<td>i</td>
<td>1122</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">14</th>
<td>it</td>
<td>1038</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="stop-words" class="slide level2">
<h2>Stop Words</h2>
<p>Words like “the”, “and”, “at” appear frequently but don’t add much context.</p>
<p>These are called <strong>stop words</strong> - they’re the “glue” of language but don’t carry meaning on their own.</p>
<p><strong>Categories of stop words:</strong></p>
<ul>
<li><strong>Articles</strong>: a, an, the</li>
<li><strong>Pronouns</strong>: I, you, he, she, it, we, they</li>
<li><strong>Prepositions</strong>: in, on, at, to, from, with</li>
<li><strong>Conjunctions</strong>: and, but, or, if, because</li>
<li><strong>Auxiliary verbs</strong>: is, are, was, were, have, has</li>
<li><strong>Common adverbs</strong>: very, just, also, now</li>
</ul>
</section>
<section id="nltks-stop-words-list" class="slide level2">
<h2>NLTK’s Stop Words List</h2>
<p>NLTK provides curated stop word lists for <strong>multiple languages</strong>:</p>
<div id="ab0e6caa" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb17-2"><a></a></span>
<span id="cb17-3"><a></a><span class="bu">print</span>(<span class="st">"Available languages:"</span>)</span>
<span id="cb17-4"><a></a><span class="bu">print</span>(stopwords.fileids())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Available languages:
['albanian', 'arabic', 'azerbaijani', 'basque', 'belarusian', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'tamil', 'turkish', 'uzbek']</code></pre>
</div>
</div>
</section>
<section id="english-stop-words" class="slide level2">
<h2>English Stop Words</h2>
<ul>
<li>Let’s get and show the English stopwords</li>
</ul>
<div id="e03fd7e5" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a></a>stop_words <span class="op">=</span> <span class="bu">set</span>(stopwords.words(<span class="st">'english'</span>))</span>
<span id="cb19-2"><a></a><span class="bu">print</span>(<span class="ss">f"Number of English stop words: </span><span class="sc">{</span><span class="bu">len</span>(stop_words)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb19-3"><a></a></span>
<span id="cb19-4"><a></a>sorted_stops <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(stop_words))</span>
<span id="cb19-5"><a></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">All English stop words:</span><span class="ch">\n</span><span class="sc">{</span>sorted_stops<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of English stop words: 198

All English stop words:
['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', "aren't", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', "couldn't", 'd', 'did', 'didn', "didn't", 'do', 'does', 'doesn', "doesn't", 'doing', 'don', "don't", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', "hadn't", 'has', 'hasn', "hasn't", 'have', 'haven', "haven't", 'having', 'he', "he'd", "he'll", "he's", 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', "i'd", "i'll", "i'm", "i've", 'if', 'in', 'into', 'is', 'isn', "isn't", 'it', "it'd", "it'll", "it's", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', "mightn't", 'more', 'most', 'mustn', "mustn't", 'my', 'myself', 'needn', "needn't", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', "shan't", 'she', "she'd", "she'll", "she's", 'should', "should've", 'shouldn', "shouldn't", 'so', 'some', 'such', 't', 'than', 'that', "that'll", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', "they'd", "they'll", "they're", "they've", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', "wasn't", 'we', "we'd", "we'll", "we're", "we've", 'were', 'weren', "weren't", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', "won't", 'wouldn', "wouldn't", 'y', 'you', "you'd", "you'll", "you're", "you've", 'your', 'yours', 'yourself', 'yourselves']</code></pre>
</div>
</div>
</section>
<section id="why-remove-stop-words" class="slide level2">
<h2>Why Remove Stop Words?</h2>
<p><strong>Benefits:</strong></p>
<ul>
<li><strong>Reduces noise</strong>: Focus on meaningful content words</li>
<li><strong>Smaller vocabulary</strong>: Faster processing, less memory</li>
<li><strong>Better results</strong>: For tasks like topic modeling, keyword extraction</li>
</ul>
<p><strong>But be careful!</strong> Sometimes stop words matter:</p>
<ul>
<li>Sentiment: “not good” vs “good” (negation matters!)</li>
<li>Phrases: “to be or not to be” loses meaning without stop words</li>
<li>Search: “The Who” (band name) vs “who” (pronoun)</li>
</ul>
</section>
<section id="top-words-before-removing-stop-words" class="slide level2">
<h2>Top Words BEFORE Removing Stop Words</h2>
<p>Let’s see what the top 15 words look like <strong>before</strong> we remove stop words:</p>
<div id="ea472f2a" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a></a>top_before <span class="op">=</span> token_counts.head(<span class="dv">15</span>).copy()</span>
<span id="cb21-2"><a></a>top_before[<span class="st">'token'</span>] <span class="op">=</span> pd.Categorical(top_before[<span class="st">'token'</span>],</span>
<span id="cb21-3"><a></a>                                      categories<span class="op">=</span>top_before[<span class="st">'token'</span>][::<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb21-4"><a></a></span>
<span id="cb21-5"><a></a>(ggplot(top_before, aes(x<span class="op">=</span><span class="st">'token'</span>, y<span class="op">=</span><span class="st">'n'</span>))</span>
<span id="cb21-6"><a></a> <span class="op">+</span> geom_col(fill<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb21-7"><a></a> <span class="op">+</span> coord_flip()</span>
<span id="cb21-8"><a></a> <span class="op">+</span> labs(x<span class="op">=</span><span class="st">'Word'</span>, y<span class="op">=</span><span class="st">'Frequency'</span>,</span>
<span id="cb21-9"><a></a>        title<span class="op">=</span><span class="st">'Top 15 Words (WITH Stop Words)'</span>)</span>
<span id="cb21-10"><a></a> <span class="op">+</span> theme_bw()</span>
<span id="cb21-11"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="JSC370-slides-06_files/figure-revealjs/cell-14-output-1.png" class="quarto-figure quarto-figure-center" width="960" height="480"></p>
</figure>
</div>
</div>
</div>
<p>Notice: The top words are all <strong>stop words</strong> like “the”, “to”, “and” - not very informative!</p>
</section>
<section id="removing-stop-words" class="slide level2">
<h2>Removing Stop Words</h2>
<p>We use a <strong>list comprehension</strong> to filter tokens. This is a concise way to create a new list by iterating through an existing one with conditions.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a></a>filtered_tokens <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> tokens</span>
<span id="cb22-2"><a></a>                   <span class="cf">if</span> t.isalpha() <span class="kw">and</span> t <span class="kw">not</span> <span class="kw">in</span> stop_words]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This reads as: <em>“Give me each token <code>t</code> from <code>tokens</code>, but only if it passes both conditions.”</em></p>
</section>
<section id="the-filtering-conditions" class="slide level2">
<h2>The Filtering Conditions</h2>
<p>Our filter applies <strong>two conditions</strong> (both must be True):</p>
<table class="caption-top">
<colgroup>
<col style="width: 26%">
<col style="width: 34%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Condition</th>
<th>What it does</th>
<th>Why we need it</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>t.isalpha()</code></td>
<td>Checks if token contains only letters</td>
<td>Removes punctuation (<code>.</code>, <code>,</code>, <code>!</code>) and numbers (<code>1</code>, <code>2025</code>)</td>
</tr>
<tr class="even">
<td><code>t not in stop_words</code></td>
<td>Checks if token is NOT a stop word</td>
<td>Removes common words like “the”, “and”, “is”</td>
</tr>
</tbody>
</table>
<p><strong>Example:</strong></p>
<ul>
<li><code>"the"</code> → <code>isalpha()</code> = True, but it’s a stop word → <strong>Removed</strong></li>
<li><code>"."</code> → <code>isalpha()</code> = False → <strong>Removed</strong></li>
<li><code>"elizabeth"</code> → <code>isalpha()</code> = True, not a stop word → <strong>Kept</strong></li>
</ul>
</section>
<section id="removing-stop-words-the-code" class="slide level2">
<h2>Removing Stop Words: The Code</h2>
<ul>
<li>Filter out stop words and non-alphabetic tokens</li>
<li>Look at the number before and after</li>
</ul>
<div id="4ca7238b" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a></a>filtered_tokens <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> tokens</span>
<span id="cb23-2"><a></a>                   <span class="cf">if</span> t.isalpha() <span class="kw">and</span> t <span class="kw">not</span> <span class="kw">in</span> stop_words]</span>
<span id="cb23-3"><a></a></span>
<span id="cb23-4"><a></a><span class="bu">print</span>(<span class="ss">f"Before filtering: </span><span class="sc">{</span><span class="bu">len</span>(tokens)<span class="sc">:,}</span><span class="ss"> tokens"</span>)</span>
<span id="cb23-5"><a></a><span class="bu">print</span>(<span class="ss">f"After filtering:  </span><span class="sc">{</span><span class="bu">len</span>(filtered_tokens)<span class="sc">:,}</span><span class="ss"> tokens"</span>)</span>
<span id="cb23-6"><a></a><span class="bu">print</span>(<span class="ss">f"Removed: </span><span class="sc">{</span><span class="bu">len</span>(tokens) <span class="op">-</span> <span class="bu">len</span>(filtered_tokens)<span class="sc">:,}</span><span class="ss"> tokens (</span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>(<span class="bu">len</span>(tokens) <span class="op">-</span> <span class="bu">len</span>(filtered_tokens))<span class="op">/</span><span class="bu">len</span>(tokens)<span class="sc">:.1f}</span><span class="ss">%)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Before filtering: 97,884 tokens
After filtering:  37,741 tokens
Removed: 60,143 tokens (61.4%)</code></pre>
</div>
</div>
</section>
<section id="counting-filtered-tokens" class="slide level2">
<h2>Counting Filtered Tokens</h2>
<p>Now we count word frequencies on the <strong>cleaned</strong> tokens:</p>
<div id="a601713c" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a></a>filtered_counts <span class="op">=</span> pd.Series(filtered_tokens).value_counts().reset_index()</span>
<span id="cb25-2"><a></a>filtered_counts.columns <span class="op">=</span> [<span class="st">'token'</span>, <span class="st">'n'</span>]</span>
<span id="cb25-3"><a></a>filtered_counts.head(<span class="dv">15</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">token</th>
<th data-quarto-table-cell-role="th">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>anne</td>
<td>497</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>could</td>
<td>451</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>would</td>
<td>355</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>captain</td>
<td>303</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>mrs</td>
<td>291</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">5</th>
<td>elliot</td>
<td>289</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">6</th>
<td>mr</td>
<td>256</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">7</th>
<td>one</td>
<td>237</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">8</th>
<td>must</td>
<td>228</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">9</th>
<td>wentworth</td>
<td>218</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">10</th>
<td>lady</td>
<td>216</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">11</th>
<td>much</td>
<td>205</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">12</th>
<td>little</td>
<td>176</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">13</th>
<td>said</td>
<td>173</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">14</th>
<td>good</td>
<td>170</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Notice how the top words are now <strong>meaningful content words</strong> instead of “the”, “and”, “to”!</p>
</section>
<section id="visualizing-top-words" class="slide level2">
<h2>Visualizing Top Words</h2>
<div id="528c3f22" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a></a>top_words <span class="op">=</span> filtered_counts.head(<span class="dv">15</span>).copy()</span>
<span id="cb26-2"><a></a>top_words[<span class="st">'token'</span>] <span class="op">=</span> pd.Categorical(top_words[<span class="st">'token'</span>],</span>
<span id="cb26-3"><a></a>                                     categories<span class="op">=</span>top_words[<span class="st">'token'</span>][::<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb26-4"><a></a></span>
<span id="cb26-5"><a></a>(ggplot(top_words, aes(x<span class="op">=</span><span class="st">'token'</span>, y<span class="op">=</span><span class="st">'n'</span>))</span>
<span id="cb26-6"><a></a> <span class="op">+</span> geom_col(fill<span class="op">=</span><span class="st">'coral'</span>)</span>
<span id="cb26-7"><a></a> <span class="op">+</span> coord_flip()</span>
<span id="cb26-8"><a></a> <span class="op">+</span> labs(x<span class="op">=</span><span class="st">'Word'</span>, y<span class="op">=</span><span class="st">'Frequency'</span>, title<span class="op">=</span><span class="st">'Top 15 Words in Persuasion'</span>)</span>
<span id="cb26-9"><a></a> <span class="op">+</span> theme_bw()</span>
<span id="cb26-10"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="JSC370-slides-06_files/figure-revealjs/cell-17-output-1.png" class="quarto-figure quarto-figure-center" width="960" height="480"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="custom-stop-words" class="slide level2">
<h2>Custom Stop Words</h2>
<p>Sometimes we need to add domain-specific stop words:</p>
<div id="cad3fbf6" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a></a><span class="co"># Add custom stop words</span></span>
<span id="cb27-2"><a></a>custom_stops <span class="op">=</span> {<span class="st">'would'</span>, <span class="st">'could'</span>, <span class="st">'one'</span>, <span class="st">'might'</span>, <span class="st">'must'</span>,</span>
<span id="cb27-3"><a></a>                <span class="st">'said'</span>, <span class="st">'mr'</span>, <span class="st">'mrs'</span>, <span class="st">'miss'</span>, <span class="st">'lady'</span>}</span>
<span id="cb27-4"><a></a></span>
<span id="cb27-5"><a></a>all_stops <span class="op">=</span> stop_words.union(custom_stops)</span>
<span id="cb27-6"><a></a></span>
<span id="cb27-7"><a></a><span class="co"># Re-filter</span></span>
<span id="cb27-8"><a></a>filtered_tokens_v2 <span class="op">=</span> [t <span class="cf">for</span> t <span class="kw">in</span> tokens</span>
<span id="cb27-9"><a></a>                      <span class="cf">if</span> t.isalpha() <span class="kw">and</span> t <span class="kw">not</span> <span class="kw">in</span> all_stops <span class="kw">and</span> <span class="bu">len</span>(t) <span class="op">&gt;</span> <span class="dv">2</span>]</span>
<span id="cb27-10"><a></a></span>
<span id="cb27-11"><a></a>filtered_counts_v2 <span class="op">=</span> pd.Series(filtered_tokens_v2).value_counts().head(<span class="dv">15</span>)</span>
<span id="cb27-12"><a></a><span class="bu">print</span>(filtered_counts_v2)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>anne         497
captain      303
elliot       289
wentworth    218
much         205
little       176
good         170
charles      166
never        154
time         151
sir          149
think        149
russell      148
well         145
walter       141
Name: count, dtype: int64</code></pre>
</div>
</div>
</section>
<section id="top-words-after-custom-stop-words" class="slide level2">
<h2>Top Words AFTER Custom Stop Words</h2>
<p>Now let’s compare: with custom stop words removed, we get even more meaningful content:</p>
<div id="dd92a6f4" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a></a><span class="co"># Prepare data for plotting</span></span>
<span id="cb29-2"><a></a>top_custom <span class="op">=</span> filtered_counts_v2.reset_index()</span>
<span id="cb29-3"><a></a>top_custom.columns <span class="op">=</span> [<span class="st">'token'</span>, <span class="st">'n'</span>]</span>
<span id="cb29-4"><a></a>top_custom[<span class="st">'token'</span>] <span class="op">=</span> pd.Categorical(top_custom[<span class="st">'token'</span>],</span>
<span id="cb29-5"><a></a>                                      categories<span class="op">=</span>top_custom[<span class="st">'token'</span>][::<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb29-6"><a></a></span>
<span id="cb29-7"><a></a>(ggplot(top_custom, aes(x<span class="op">=</span><span class="st">'token'</span>, y<span class="op">=</span><span class="st">'n'</span>))</span>
<span id="cb29-8"><a></a> <span class="op">+</span> geom_col(fill<span class="op">=</span><span class="st">'seagreen'</span>)</span>
<span id="cb29-9"><a></a> <span class="op">+</span> coord_flip()</span>
<span id="cb29-10"><a></a> <span class="op">+</span> labs(x<span class="op">=</span><span class="st">'Word'</span>, y<span class="op">=</span><span class="st">'Frequency'</span>,</span>
<span id="cb29-11"><a></a>        title<span class="op">=</span><span class="st">'Top 15 Words (After Custom Stop Words)'</span>)</span>
<span id="cb29-12"><a></a> <span class="op">+</span> theme_bw()</span>
<span id="cb29-13"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="JSC370-slides-06_files/figure-revealjs/cell-19-output-1.png" class="quarto-figure quarto-figure-center" width="960" height="480"></p>
</figure>
</div>
</div>
</div>
<p>Compare to the previous plot: words like “would”, “could”, “said” are now removed!</p>
</section>
<section id="word-cloud" class="slide level2">
<h2>Word Cloud</h2>
<ul>
<li>This is a visualization that you often see to illustrate popular words</li>
</ul>
<div id="cb6d5e40" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud</span>
<span id="cb30-2"><a></a></span>
<span id="cb30-3"><a></a><span class="co"># Create word frequency dictionary</span></span>
<span id="cb30-4"><a></a>word_freq <span class="op">=</span> <span class="bu">dict</span>(pd.Series(filtered_tokens_v2).value_counts().head(<span class="dv">100</span>))</span>
<span id="cb30-5"><a></a></span>
<span id="cb30-6"><a></a><span class="co"># Generate word cloud</span></span>
<span id="cb30-7"><a></a>wordcloud <span class="op">=</span> WordCloud(width<span class="op">=</span><span class="dv">800</span>, height<span class="op">=</span><span class="dv">400</span>,</span>
<span id="cb30-8"><a></a>                      background_color<span class="op">=</span><span class="st">'white'</span>,</span>
<span id="cb30-9"><a></a>                      colormap<span class="op">=</span><span class="st">'viridis'</span>).generate_from_frequencies(word_freq)</span>
<span id="cb30-10"><a></a></span>
<span id="cb30-11"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb30-12"><a></a>plt.imshow(wordcloud, interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb30-13"><a></a>plt.axis(<span class="st">'off'</span>)</span>
<span id="cb30-14"><a></a>plt.title(<span class="st">'Word Cloud - Persuasion'</span>)</span>
<span id="cb30-15"><a></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="JSC370-slides-06_files/figure-revealjs/cell-20-output-1.png" class="quarto-figure quarto-figure-center" width="906" height="483"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="n-grams" class="slide level2">
<h2>N-grams</h2>
<p><strong>N-grams</strong> are n consecutive words that appear together:</p>
<ul>
<li><strong>Unigrams</strong> (n=1): “which”, “words”, “appear”</li>
<li><strong>Bigrams</strong> (n=2): “which words”, “words appear”</li>
<li><strong>Trigrams</strong> (n=3): “which words appear”</li>
</ul>
</section>
<section id="n-grams-filtered-or-unfiltered" class="slide level2">
<h2>N-grams: Filtered or Unfiltered?</h2>
<p><strong>Should we remove stop words before computing n-grams?</strong></p>
<table class="caption-top">
<colgroup>
<col style="width: 45%">
<col style="width: 27%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th>Approach</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>With stop words</strong></td>
<td>Preserves phrases like “to be or not to be”, “the United States”</td>
<td>Dominated by uninteresting pairs like “of the”, “in a”</td>
</tr>
<tr class="even">
<td><strong>Without stop words</strong></td>
<td>Focuses on meaningful content word pairs</td>
<td>May miss important phrases; words that weren’t adjacent become “adjacent”</td>
</tr>
</tbody>
</table>
<p><strong>Our choice:</strong> We’ll use filtered tokens to focus on <strong>meaningful word pairs</strong>.</p>
</section>
<section id="extracting-bigrams" class="slide level2">
<h2>Extracting Bigrams</h2>
<ul>
<li>Generate bigrams from filtered tokens (stop words removed)</li>
</ul>
<div id="6c821285" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a></a><span class="im">from</span> nltk <span class="im">import</span> ngrams</span>
<span id="cb31-2"><a></a></span>
<span id="cb31-3"><a></a></span>
<span id="cb31-4"><a></a>bigrams <span class="op">=</span> <span class="bu">list</span>(ngrams(filtered_tokens_v2, <span class="dv">2</span>))</span>
<span id="cb31-5"><a></a>bigram_counts <span class="op">=</span> Counter(bigrams).most_common(<span class="dv">15</span>)</span>
<span id="cb31-6"><a></a></span>
<span id="cb31-7"><a></a><span class="bu">print</span>(<span class="st">"Top 15 Bigrams (from filtered tokens):"</span>)</span>
<span id="cb31-8"><a></a><span class="cf">for</span> bigram, count <span class="kw">in</span> bigram_counts:</span>
<span id="cb31-9"><a></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span><span class="st">' '</span><span class="sc">.</span>join(bigram)<span class="sc">:30}</span><span class="ss"> </span><span class="sc">{</span>count<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 15 Bigrams (from filtered tokens):
  captain wentworth              196
  sir walter                     131
  captain benwick                56
  captain harville               41
  great deal                     34
  charles hayter                 33
  camden place                   29
  kellynch hall                  25
  anne elliot                    24
  colonel wallis                 23
  young man                      22
  admiral croft                  20
  walter elliot                  18
  father sister                  15
  louisa musgrove                15</code></pre>
</div>
</div>
<p>Note: These pairs weren’t necessarily adjacent in the original text - words between them may have been removed!</p>
</section>
<section id="visualizing-bigrams" class="slide level2">
<h2>Visualizing Bigrams</h2>
<div id="031ea013" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a></a>bigram_df <span class="op">=</span> pd.DataFrame(bigram_counts, columns<span class="op">=</span>[<span class="st">'bigram'</span>, <span class="st">'count'</span>])</span>
<span id="cb33-2"><a></a>bigram_df[<span class="st">'bigram'</span>] <span class="op">=</span> bigram_df[<span class="st">'bigram'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">' '</span>.join(x))</span>
<span id="cb33-3"><a></a>bigram_df[<span class="st">'bigram'</span>] <span class="op">=</span> pd.Categorical(bigram_df[<span class="st">'bigram'</span>],</span>
<span id="cb33-4"><a></a>                                      categories<span class="op">=</span>bigram_df[<span class="st">'bigram'</span>][::<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb33-5"><a></a></span>
<span id="cb33-6"><a></a>(ggplot(bigram_df, aes(x<span class="op">=</span><span class="st">'bigram'</span>, y<span class="op">=</span><span class="st">'count'</span>))</span>
<span id="cb33-7"><a></a> <span class="op">+</span> geom_col(fill<span class="op">=</span><span class="st">'steelblue'</span>)</span>
<span id="cb33-8"><a></a> <span class="op">+</span> coord_flip()</span>
<span id="cb33-9"><a></a> <span class="op">+</span> labs(x<span class="op">=</span><span class="st">'Bigram'</span>, y<span class="op">=</span><span class="st">'Frequency'</span>, title<span class="op">=</span><span class="st">'Top 15 Bigrams in Persuasion'</span>)</span>
<span id="cb33-10"><a></a> <span class="op">+</span> theme_bw()</span>
<span id="cb33-11"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="JSC370-slides-06_files/figure-revealjs/cell-22-output-1.png" class="quarto-figure quarto-figure-center" width="960" height="480"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="the-problem-with-word-counts" class="slide level2">
<h2>The Problem with Word Counts</h2>
<p>Simple word frequency has a limitation: <strong>it treats all documents the same</strong>.</p>
<p>Consider analyzing chapters in a book:</p>
<ul>
<li>A word like “anne” might appear frequently in Chapter 5</li>
<li>But if “anne” appears in <em>every</em> chapter, it’s not distinctive to Chapter 5</li>
<li>We want to find words that are <strong>important to specific documents</strong></li>
</ul>
<p><strong>Solution:</strong> TF-IDF weights words by how unique they are across documents.</p>
</section>
<section id="why-use-tf-idf" class="slide level2">
<h2>Why Use TF-IDF?</h2>
<p><strong>Use cases:</strong></p>
<ul>
<li><strong>Document comparison</strong>: What makes each chapter/document unique?</li>
<li><strong>Search engines</strong>: Rank documents by relevance to a query</li>
<li><strong>Feature engineering</strong>: Convert text to numbers for machine learning</li>
<li><strong>Keyword extraction</strong>: Find the most distinctive terms</li>
</ul>
<p>TF-IDF answers: <em>“What words are important in THIS document compared to others?”</em></p>
</section>
<section id="tf-idf" class="slide level2">
<h2>TF-IDF</h2>
<p><strong>Term Frequency (TF)</strong>: How often a word appears in a document</p>
<p><span class="math display">\[TF = \frac{\text{Term count in document}}{\text{Total terms in document}}\]</span></p>
<p><strong>Inverse Document Frequency (IDF)</strong>: How rare a word is across documents</p>
<p><span class="math display">\[IDF = \log\left(\frac{\text{Total documents}}{\text{Documents containing term}}\right)\]</span></p>
</section>
<section id="tf-idf-combined" class="slide level2">
<h2>TF-IDF Combined</h2>
<p><span class="math display">\[\text{TF-IDF} = TF \times IDF\]</span></p>
<ul>
<li><strong>High TF-IDF</strong>: Important word in a specific document</li>
<li><strong>Low TF-IDF</strong>: Common word with less importance</li>
</ul>
</section>
<section id="tf-idf-with-scikit-learn" class="slide level2">
<h2>TF-IDF with scikit-learn</h2>
<div id="85dfaaa1" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb34-2"><a></a></span>
<span id="cb34-3"><a></a><span class="co"># Create TF-IDF matrix by chapter</span></span>
<span id="cb34-4"><a></a>vectorizer <span class="op">=</span> TfidfVectorizer(stop_words<span class="op">=</span><span class="st">'english'</span>, max_features<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb34-5"><a></a>tfidf_matrix <span class="op">=</span> vectorizer.fit_transform(text_df[<span class="st">'text'</span>])</span>
<span id="cb34-6"><a></a></span>
<span id="cb34-7"><a></a><span class="co"># Get feature names</span></span>
<span id="cb34-8"><a></a>feature_names <span class="op">=</span> vectorizer.get_feature_names_out()</span>
<span id="cb34-9"><a></a><span class="bu">print</span>(<span class="ss">f"Vocabulary size: </span><span class="sc">{</span><span class="bu">len</span>(feature_names)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Vocabulary size: 1000</code></pre>
</div>
</div>
</section>
<section id="top-tf-idf-words-by-chapter" class="slide level2">
<h2>Top TF-IDF Words by Chapter</h2>
<div id="83922a92" class="cell" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a></a><span class="co"># Get top words for first 4 chapters</span></span>
<span id="cb36-2"><a></a><span class="kw">def</span> get_top_tfidf(chapter_idx, n<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb36-3"><a></a>    row <span class="op">=</span> tfidf_matrix[chapter_idx].toarray().flatten()</span>
<span id="cb36-4"><a></a>    top_indices <span class="op">=</span> row.argsort()[<span class="op">-</span>n:][::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb36-5"><a></a>    <span class="cf">return</span> [(feature_names[i], row[i]) <span class="cf">for</span> i <span class="kw">in</span> top_indices]</span>
<span id="cb36-6"><a></a></span>
<span id="cb36-7"><a></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">min</span>(<span class="dv">4</span>, <span class="bu">len</span>(text_df))):</span>
<span id="cb36-8"><a></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Chapter </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb36-9"><a></a>    <span class="cf">for</span> word, score <span class="kw">in</span> get_top_tfidf(i):</span>
<span id="cb36-10"><a></a>        <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>word<span class="sc">:15}</span><span class="ss"> </span><span class="sc">{</span>score<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Chapter 1:
  walter          0.3480
  elliot          0.2973
  sir             0.2862
  elizabeth       0.2420
  father          0.1904

Chapter 2:
  walter          0.3599
  sir             0.3452
  russell         0.2679
  lady            0.2374
  elizabeth       0.1778

Chapter 3:
  shepherd        0.4495
  sir             0.3372
  walter          0.3164
  admiral         0.2906
  tenant          0.2748

Chapter 4:
  anne            0.2410
  russell         0.2358
  lady            0.2090
  engagement      0.2030
  profession      0.1624</code></pre>
</div>
</div>
</section>
<section id="sentiment-analysis" class="slide level2">
<h2>Sentiment Analysis</h2>
<p>Extracting opinions and emotions from text:</p>
<ul>
<li><strong>Positive / Negative / Neutral</strong> classification</li>
<li><strong>Emotion categories</strong>: joy, anger, fear, sadness, etc.</li>
<li><strong>Intensity scores</strong>: How strongly positive or negative</li>
</ul>
</section>
<section id="vader-sentiment-analysis" class="slide level2">
<h2>VADER Sentiment Analysis</h2>
<p><strong>VADER</strong> (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon-based sentiment analyzer designed for social media and general text.</p>
<p><strong>How it works:</strong></p>
<ul>
<li>Uses a dictionary of words with pre-assigned sentiment scores</li>
<li>Handles negations (“not good” <span class="math inline">\(\rightarrow\)</span> negative)</li>
<li>Understands intensifiers (“very good” <span class="math inline">\(\rightarrow\)</span> more positive)</li>
<li>Recognizes punctuation and capitalization (“GREAT!!!” <span class="math inline">\(\rightarrow\)</span> very positive)</li>
</ul>
</section>
<section id="vader-output-four-scores" class="slide level2">
<h2>VADER Output: Four Scores</h2>
<p>VADER returns <strong>four scores</strong> for each text:</p>
<table class="caption-top">
<colgroup>
<col style="width: 30%">
<col style="width: 30%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Score</th>
<th>Range</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>neg</code></td>
<td>0 to 1</td>
<td>Proportion of text that is negative</td>
</tr>
<tr class="even">
<td><code>neu</code></td>
<td>0 to 1</td>
<td>Proportion of text that is neutral</td>
</tr>
<tr class="odd">
<td><code>pos</code></td>
<td>0 to 1</td>
<td>Proportion of text that is positive</td>
</tr>
<tr class="even">
<td><code>compound</code></td>
<td>-1 to +1</td>
<td><strong>Overall sentiment</strong> (normalized, weighted composite)</td>
</tr>
</tbody>
</table>
<p>The <code>neg</code>, <code>neu</code>, and <code>pos</code> scores sum to 1.0.</p>
</section>
<section id="the-compound-score" class="slide level2">
<h2>The Compound Score</h2>
<p>The <strong>compound score</strong> is the most useful single metric:</p>
<ul>
<li>Computed by summing all word scores, adjusting for rules, then normalizing</li>
<li>Ranges from <strong>-1</strong> (extremely negative) to <strong>+1</strong> (extremely positive)</li>
</ul>
<p><strong>Interpretation thresholds:</strong></p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Compound Score</th>
<th>Sentiment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&gt;= 0.05</td>
<td>Positive</td>
</tr>
<tr class="even">
<td>&lt;= -0.05</td>
<td>Negative</td>
</tr>
<tr class="odd">
<td>Between -0.05 and 0.05</td>
<td>Neutral</td>
</tr>
</tbody>
</table>
</section>
<section id="vader-example" class="slide level2">
<h2>VADER Example</h2>
<p>Let’s see how VADER scores some sentences</p>
<div id="a0f49f52" class="cell" data-execution_count="24">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a></a><span class="im">from</span> nltk.sentiment.vader <span class="im">import</span> SentimentIntensityAnalyzer</span>
<span id="cb38-2"><a></a>sia <span class="op">=</span> SentimentIntensityAnalyzer()</span>
<span id="cb38-3"><a></a></span>
<span id="cb38-4"><a></a></span>
<span id="cb38-5"><a></a>examples <span class="op">=</span> [</span>
<span id="cb38-6"><a></a>    <span class="st">"I love this book!"</span>,</span>
<span id="cb38-7"><a></a>    <span class="st">"This is okay."</span>,</span>
<span id="cb38-8"><a></a>    <span class="st">"I hate this terrible weather."</span>,</span>
<span id="cb38-9"><a></a>    <span class="st">"The movie was not good."</span>,</span>
<span id="cb38-10"><a></a>    <span class="st">"The movie was not bad."</span></span>
<span id="cb38-11"><a></a>]</span>
<span id="cb38-12"><a></a></span>
<span id="cb38-13"><a></a><span class="cf">for</span> text <span class="kw">in</span> examples:</span>
<span id="cb38-14"><a></a>    scores <span class="op">=</span> sia.polarity_scores(text)</span>
<span id="cb38-15"><a></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>text<span class="sc">:35}</span><span class="ss"> → compound: </span><span class="sc">{</span>scores[<span class="st">'compound'</span>]<span class="sc">:+.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>I love this book!                   → compound: +0.670
This is okay.                       → compound: +0.226
I hate this terrible weather.       → compound: -0.778
The movie was not good.             → compound: -0.341
The movie was not bad.              → compound: +0.431</code></pre>
</div>
</div>
</section>
<section id="the-problem-with-long-texts" class="slide level2">
<h2>The Problem with Long Texts</h2>
<p><strong>VADER is designed for short texts</strong> (tweets, reviews, sentences).</p>
<p>When analyzing entire chapters:</p>
<ul>
<li>The compound score tends to <strong>saturate</strong> at +1 or -1</li>
<li>Long texts contain both positive and negative sentences</li>
<li>The normalization doesn’t work well for thousands of words</li>
</ul>
<p><strong>Solution:</strong> Analyze at the <strong>sentence level</strong>, then aggregate per chapter.</p>
</section>
<section id="sentence-tokenization" class="slide level2">
<h2>Sentence Tokenization</h2>
<p>NLTK’s <code>sent_tokenize()</code> splits text into sentences using:</p>
<ul>
<li><strong>Punctuation patterns</strong>: Periods, question marks, exclamation points</li>
<li><strong>Abbreviation handling</strong>: Knows “Dr.” and “Mrs.” aren’t sentence endings</li>
<li><strong>Trained model</strong>: Uses the Punkt tokenizer trained on English text</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a></a>sent_tokenize(<span class="st">"Dr. Smith went home. She was tired."</span>)</span>
<span id="cb40-2"><a></a><span class="co"># Returns: ["Dr. Smith went home.", "She was tired."]</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="sentence-level-sentiment-analysis" class="slide level2">
<h2>Sentence-Level Sentiment Analysis</h2>
<div id="a787feda" class="cell" data-execution_count="25">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> sent_tokenize</span>
<span id="cb41-2"><a></a></span>
<span id="cb41-3"><a></a>sentence_sentiments <span class="op">=</span> []</span>
<span id="cb41-4"><a></a></span>
<span id="cb41-5"><a></a><span class="cf">for</span> _, row <span class="kw">in</span> text_df.iterrows():</span>
<span id="cb41-6"><a></a>    <span class="co"># Split chapter into individual sentences</span></span>
<span id="cb41-7"><a></a>    sentences <span class="op">=</span> sent_tokenize(row[<span class="st">'text'</span>])</span>
<span id="cb41-8"><a></a>    <span class="co"># Score each sentence separately</span></span>
<span id="cb41-9"><a></a>    <span class="cf">for</span> sent <span class="kw">in</span> sentences:</span>
<span id="cb41-10"><a></a>        scores <span class="op">=</span> sia.polarity_scores(sent)</span>
<span id="cb41-11"><a></a>        scores[<span class="st">'chapter'</span>] <span class="op">=</span> row[<span class="st">'chapter'</span>]</span>
<span id="cb41-12"><a></a>        sentence_sentiments.append(scores)</span>
<span id="cb41-13"><a></a></span>
<span id="cb41-14"><a></a>sentence_df <span class="op">=</span> pd.DataFrame(sentence_sentiments)</span>
<span id="cb41-15"><a></a><span class="bu">print</span>(<span class="ss">f"Total sentences analyzed: </span><span class="sc">{</span><span class="bu">len</span>(sentence_df)<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb41-16"><a></a>sentence_df.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total sentences analyzed: 3,654</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="64">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">neg</th>
<th data-quarto-table-cell-role="th">neu</th>
<th data-quarto-table-cell-role="th">pos</th>
<th data-quarto-table-cell-role="th">compound</th>
<th data-quarto-table-cell-role="th">chapter</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>0.167</td>
<td>0.671</td>
<td>0.162</td>
<td>-0.1814</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>0.000</td>
<td>1.000</td>
<td>0.000</td>
<td>0.0000</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>0.000</td>
<td>1.000</td>
<td>0.000</td>
<td>0.0000</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>0.091</td>
<td>0.909</td>
<td>0.000</td>
<td>-0.5574</td>
<td>1</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>0.000</td>
<td>0.917</td>
<td>0.083</td>
<td>0.6310</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="aggregating-by-chapter" class="slide level2">
<h2>Aggregating by Chapter</h2>
<p>Let’s calculate the mean sentiment score by chapter</p>
<div id="a39e5338" class="cell" data-execution_count="26">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a></a>chapter_sentiment <span class="op">=</span> sentence_df.groupby(<span class="st">'chapter'</span>).agg({</span>
<span id="cb43-2"><a></a>    <span class="st">'compound'</span>: <span class="st">'mean'</span>,</span>
<span id="cb43-3"><a></a>    <span class="st">'pos'</span>: <span class="st">'mean'</span>,</span>
<span id="cb43-4"><a></a>    <span class="st">'neg'</span>: <span class="st">'mean'</span>,</span>
<span id="cb43-5"><a></a>    <span class="st">'neu'</span>: <span class="st">'mean'</span></span>
<span id="cb43-6"><a></a>}).reset_index()</span>
<span id="cb43-7"><a></a></span>
<span id="cb43-8"><a></a>chapter_sentiment</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">chapter</th>
<th data-quarto-table-cell-role="th">compound</th>
<th data-quarto-table-cell-role="th">pos</th>
<th data-quarto-table-cell-role="th">neg</th>
<th data-quarto-table-cell-role="th">neu</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>1</td>
<td>0.153892</td>
<td>0.108452</td>
<td>0.073082</td>
<td>0.818493</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>2</td>
<td>0.184853</td>
<td>0.113657</td>
<td>0.057000</td>
<td>0.829357</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>3</td>
<td>0.198065</td>
<td>0.136343</td>
<td>0.065210</td>
<td>0.798467</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>4</td>
<td>0.243536</td>
<td>0.148491</td>
<td>0.093891</td>
<td>0.757655</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>5</td>
<td>0.191471</td>
<td>0.126071</td>
<td>0.057893</td>
<td>0.816021</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">5</th>
<td>6</td>
<td>0.249289</td>
<td>0.137467</td>
<td>0.065346</td>
<td>0.797187</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">6</th>
<td>7</td>
<td>0.132271</td>
<td>0.109803</td>
<td>0.080230</td>
<td>0.809967</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">7</th>
<td>8</td>
<td>0.148624</td>
<td>0.139420</td>
<td>0.066337</td>
<td>0.794272</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">8</th>
<td>9</td>
<td>0.173656</td>
<td>0.113330</td>
<td>0.058816</td>
<td>0.827854</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">9</th>
<td>10</td>
<td>0.171978</td>
<td>0.131333</td>
<td>0.068109</td>
<td>0.800552</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">10</th>
<td>11</td>
<td>0.325292</td>
<td>0.129515</td>
<td>0.052197</td>
<td>0.818318</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">11</th>
<td>12</td>
<td>0.155733</td>
<td>0.112237</td>
<td>0.054796</td>
<td>0.832959</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">12</th>
<td>13</td>
<td>0.183183</td>
<td>0.131789</td>
<td>0.058342</td>
<td>0.809886</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">13</th>
<td>14</td>
<td>0.159982</td>
<td>0.115982</td>
<td>0.054366</td>
<td>0.829643</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">14</th>
<td>15</td>
<td>0.203798</td>
<td>0.124135</td>
<td>0.054173</td>
<td>0.821677</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">15</th>
<td>16</td>
<td>0.269217</td>
<td>0.147580</td>
<td>0.059790</td>
<td>0.792590</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">16</th>
<td>17</td>
<td>0.220112</td>
<td>0.139307</td>
<td>0.070679</td>
<td>0.790057</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">17</th>
<td>18</td>
<td>0.196745</td>
<td>0.123020</td>
<td>0.050412</td>
<td>0.826557</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">18</th>
<td>19</td>
<td>0.099329</td>
<td>0.075658</td>
<td>0.071623</td>
<td>0.852746</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">19</th>
<td>20</td>
<td>0.132032</td>
<td>0.121000</td>
<td>0.080577</td>
<td>0.798402</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">20</th>
<td>21</td>
<td>0.155444</td>
<td>0.120880</td>
<td>0.057540</td>
<td>0.821599</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">21</th>
<td>22</td>
<td>0.157241</td>
<td>0.131444</td>
<td>0.076787</td>
<td>0.791752</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">22</th>
<td>23</td>
<td>0.117682</td>
<td>0.119438</td>
<td>0.080959</td>
<td>0.799621</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">23</th>
<td>24</td>
<td>0.469696</td>
<td>0.197426</td>
<td>0.075468</td>
<td>0.727149</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Now we have <strong>average sentiment per chapter</strong> based on all sentences!</p>
</section>
<section id="sentiment-across-chapters" class="slide level2">
<h2>Sentiment Across Chapters</h2>
<div id="ffd16d1c" class="cell" data-execution_count="27">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a></a>(ggplot(chapter_sentiment, aes(x<span class="op">=</span><span class="st">'chapter'</span>, y<span class="op">=</span><span class="st">'compound'</span>))</span>
<span id="cb44-2"><a></a> <span class="op">+</span> geom_line(color<span class="op">=</span><span class="st">'purple'</span>, size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb44-3"><a></a> <span class="op">+</span> geom_point(color<span class="op">=</span><span class="st">'purple'</span>, size<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb44-4"><a></a> <span class="op">+</span> geom_hline(yintercept<span class="op">=</span><span class="dv">0</span>, linetype<span class="op">=</span><span class="st">'dashed'</span>, color<span class="op">=</span><span class="st">'gray'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb44-5"><a></a> <span class="op">+</span> labs(x<span class="op">=</span><span class="st">'Chapter'</span>, y<span class="op">=</span><span class="st">'Mean Compound Sentiment Score'</span>,</span>
<span id="cb44-6"><a></a>        title<span class="op">=</span><span class="st">'Sentiment Arc in Persuasion (Sentence-Level Aggregation)'</span>)</span>
<span id="cb44-7"><a></a> <span class="op">+</span> theme_bw()</span>
<span id="cb44-8"><a></a> <span class="op">+</span> theme(figure_size<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb44-9"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="JSC370-slides-06_files/figure-revealjs/cell-28-output-1.png" class="quarto-figure quarto-figure-center" width="960" height="480"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="topic-modeling" class="slide level2">
<h2>Topic Modeling</h2>
<p><strong>What is it?</strong> An unsupervised method to discover abstract “topics” in a collection of documents.</p>
<p><strong>Use cases:</strong></p>
<ul>
<li><strong>Document organization</strong>: Automatically categorize articles, emails, reviews</li>
<li><strong>Content recommendation</strong>: Find similar documents based on topics</li>
<li><strong>Trend analysis</strong>: Track how topics change over time</li>
<li><strong>Exploratory analysis</strong>: Understand what a corpus is about</li>
</ul>
</section>
<section id="latent-dirichlet-allocation-lda" class="slide level2 scrollable">
<h2>Latent Dirichlet Allocation (LDA)</h2>
<p>The most popular topic modeling algorithm. <strong>Key assumptions:</strong></p>
<ol type="1">
<li>Each <strong>document</strong> is a mixture of topics
<ul>
<li>Chapter 1 might be 60% “romance”, 30% “family”, 10% “society”</li>
</ul></li>
<li>Each <strong>topic</strong> is a mixture of words
<ul>
<li>“Romance” topic: love, heart, feeling, affection, …</li>
<li>“Family” topic: father, sister, mother, home, …</li>
</ul></li>
<li>Topics are <strong>latent</strong> (hidden) - we discover them from word patterns</li>
</ol>
</section>
<section id="how-lda-works" class="slide level2 scrollable">
<h2>How LDA Works</h2>
<p>LDA is a <strong>generative model</strong> - it imagines how documents were created:</p>
<ol type="1">
<li>For each document, randomly choose a topic mixture</li>
<li>For each word position:
<ul>
<li>Pick a topic based on the document’s mixture</li>
<li>Pick a word based on that topic’s word distribution</li>
</ul></li>
</ol>
<p><strong>In practice:</strong> LDA works <em>backwards</em> - given documents, it infers the topics that likely generated them.</p>
</section>
<section id="the-document-term-matrix" class="slide level2">
<h2>The Document-Term Matrix</h2>
<p>LDA needs a <strong>document-term matrix (DTM)</strong> as input:</p>
<table class="caption-top">
<thead>
<tr class="header">
<th></th>
<th>word1</th>
<th>word2</th>
<th>word3</th>
<th>…</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Doc 1</td>
<td>3</td>
<td>0</td>
<td>5</td>
<td>…</td>
</tr>
<tr class="even">
<td>Doc 2</td>
<td>0</td>
<td>2</td>
<td>1</td>
<td>…</td>
</tr>
<tr class="odd">
<td>Doc 3</td>
<td>1</td>
<td>4</td>
<td>0</td>
<td>…</td>
</tr>
</tbody>
</table>
<ul>
<li>Rows = documents (chapters)</li>
<li>Columns = words in vocabulary</li>
<li>Values = word counts (or frequencies)</li>
</ul>
</section>
<section id="creating-the-document-term-matrix" class="slide level2">
<h2>Creating the Document-Term Matrix</h2>
<div id="d6676a34" class="cell" data-execution_count="28">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> LatentDirichletAllocation</span>
<span id="cb45-2"><a></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb45-3"><a></a></span>
<span id="cb45-4"><a></a>count_vec <span class="op">=</span> CountVectorizer(stop_words<span class="op">=</span><span class="st">'english'</span>, max_features<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb45-5"><a></a>dtm <span class="op">=</span> count_vec.fit_transform(text_df[<span class="st">'text'</span>])</span>
<span id="cb45-6"><a></a></span>
<span id="cb45-7"><a></a><span class="bu">print</span>(<span class="ss">f"DTM shape: </span><span class="sc">{</span>dtm<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb45-8"><a></a><span class="bu">print</span>(<span class="ss">f"  - </span><span class="sc">{</span>dtm<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> documents (chapters)"</span>)</span>
<span id="cb45-9"><a></a><span class="bu">print</span>(<span class="ss">f"  - </span><span class="sc">{</span>dtm<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> unique words in vocabulary"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>DTM shape: (24, 500)
  - 24 documents (chapters)
  - 500 unique words in vocabulary</code></pre>
</div>
</div>
</section>
<section id="choosing-the-number-of-topics" class="slide level2">
<h2>Choosing the Number of Topics</h2>
<p><strong>The <code>n_topics</code> parameter</strong> is a hyperparameter you must choose:</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Few topics (2-3)</th>
<th>Many topics (10+)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Broad, general themes</td>
<td>Specific, narrow themes</td>
</tr>
<tr class="even">
<td>Easier to interpret</td>
<td>May capture nuances</td>
</tr>
<tr class="odd">
<td>Topics may blend together</td>
<td>Topics may be redundant</td>
</tr>
</tbody>
</table>
<p><strong>Tips:</strong></p>
<ul>
<li>Start with a small number and increase if topics are too broad</li>
<li>There’s no “correct” answer - it depends on your use case</li>
<li>Use domain knowledge to evaluate if topics make sense</li>
</ul>
</section>
<section id="fitting-the-lda-model" class="slide level2">
<h2>Fitting the LDA Model</h2>
<p>Fit LDA model with 4 topics:</p>
<div id="b7aebfab" class="cell" data-execution_count="29">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a></a>n_topics <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb47-2"><a></a>lda <span class="op">=</span> LatentDirichletAllocation(</span>
<span id="cb47-3"><a></a>    n_components<span class="op">=</span>n_topics,</span>
<span id="cb47-4"><a></a>    random_state<span class="op">=</span><span class="dv">42</span>,       <span class="co"># seed</span></span>
<span id="cb47-5"><a></a>    max_iter<span class="op">=</span><span class="dv">10</span>            <span class="co"># number of iterations</span></span>
<span id="cb47-6"><a></a>)</span>
<span id="cb47-7"><a></a>lda.fit(dtm)</span>
<span id="cb47-8"><a></a></span>
<span id="cb47-9"><a></a><span class="bu">print</span>(<span class="ss">f"Model fitted with </span><span class="sc">{</span>n_topics<span class="sc">}</span><span class="ss"> topics"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model fitted with 4 topics</code></pre>
</div>
</div>
</section>
<section id="visualizing-topics" class="slide level2">
<h2>Visualizing Topics</h2>
<ul>
<li>Create a DataFrame</li>
<li>Create ordered factor for words within each topic</li>
<li>Visualize</li>
</ul>
<div id="ea60c9c0" class="cell" data-execution_count="30">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a></a>feature_names <span class="op">=</span> count_vec.get_feature_names_out()</span>
<span id="cb49-2"><a></a></span>
<span id="cb49-3"><a></a>topic_data <span class="op">=</span> []</span>
<span id="cb49-4"><a></a><span class="cf">for</span> topic_idx, topic <span class="kw">in</span> <span class="bu">enumerate</span>(lda.components_):</span>
<span id="cb49-5"><a></a>    top_words_idx <span class="op">=</span> topic.argsort()[<span class="op">-</span><span class="dv">10</span>:][::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb49-6"><a></a>    <span class="cf">for</span> rank, idx <span class="kw">in</span> <span class="bu">enumerate</span>(top_words_idx):</span>
<span id="cb49-7"><a></a>        topic_data.append({</span>
<span id="cb49-8"><a></a>            <span class="st">'topic'</span>: <span class="ss">f'Topic </span><span class="sc">{</span>topic_idx <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb49-9"><a></a>            <span class="st">'word'</span>: feature_names[idx],</span>
<span id="cb49-10"><a></a>            <span class="st">'weight'</span>: topic[idx],</span>
<span id="cb49-11"><a></a>            <span class="st">'rank'</span>: rank</span>
<span id="cb49-12"><a></a>        })</span>
<span id="cb49-13"><a></a></span>
<span id="cb49-14"><a></a>topic_df <span class="op">=</span> pd.DataFrame(topic_data)</span>
<span id="cb49-15"><a></a></span>
<span id="cb49-16"><a></a></span>
<span id="cb49-17"><a></a>topic_df[<span class="st">'word_ordered'</span>] <span class="op">=</span> pd.Categorical(</span>
<span id="cb49-18"><a></a>    topic_df[<span class="st">'word'</span>],</span>
<span id="cb49-19"><a></a>    categories<span class="op">=</span>topic_df.sort_values([<span class="st">'topic'</span>, <span class="st">'weight'</span>])[<span class="st">'word'</span>].unique()</span>
<span id="cb49-20"><a></a>)</span>
<span id="cb49-21"><a></a></span>
<span id="cb49-22"><a></a>(ggplot(topic_df, aes(x<span class="op">=</span><span class="st">'reorder(word, weight)'</span>, y<span class="op">=</span><span class="st">'weight'</span>, fill<span class="op">=</span><span class="st">'topic'</span>))</span>
<span id="cb49-23"><a></a> <span class="op">+</span> geom_col(show_legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb49-24"><a></a> <span class="op">+</span> coord_flip()</span>
<span id="cb49-25"><a></a> <span class="op">+</span> facet_wrap(<span class="st">'~topic'</span>, scales<span class="op">=</span><span class="st">'free'</span>)</span>
<span id="cb49-26"><a></a> <span class="op">+</span> labs(x<span class="op">=</span><span class="st">''</span>, y<span class="op">=</span><span class="st">'Weight'</span>, title<span class="op">=</span><span class="st">'Top Words by Topic'</span>)</span>
<span id="cb49-27"><a></a> <span class="op">+</span> theme_bw()</span>
<span id="cb49-28"><a></a> <span class="op">+</span> theme(figure_size<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb49-29"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="JSC370-slides-06_files/figure-revealjs/cell-31-output-1.png" class="quarto-figure quarto-figure-center" width="1152" height="768"></p>
</figure>
</div>
</div>
</div>
</section>
<section class="slide level2">

</section>
<section>
<section id="large-language-models-llms" class="title-slide slide level1 center">
<h1>Large Language Models (LLMs)</h1>

</section>
<section id="what-are-llms" class="slide level2">
<h2>What are LLMs?</h2>
<p>Large Language Models are neural networks trained on massive text corpora that can:</p>
<ul>
<li><strong>Generate</strong> coherent, contextual text</li>
<li><strong>Summarize</strong> documents</li>
<li><strong>Classify</strong> text into categories</li>
<li><strong>Answer questions</strong> about content</li>
<li><strong>Extract</strong> structured information</li>
<li>Create <strong>embeddings</strong> for semantic search</li>
</ul>
</section>
<section id="llm-apis" class="slide level2">
<h2>LLM APIs</h2>
<p>Popular LLM providers:</p>
<ul>
<li><strong>Anthropic</strong>: Claude (claude-sonnet-4-20250514)</li>
<li><strong>OpenAI</strong>: GPT-5.2, GPT-4o-mini</li>
<li><strong>Google</strong>: Gemini</li>
<li><strong>Open Source</strong>: Llama, Mistral, DeepSeek</li>
</ul>
</section>
<section id="how-llm-apis-work" class="slide level2 scrollable">
<h2>How LLM APIs Work</h2>
<ol type="1">
<li><strong>Authentication</strong>: You get an API key from the provider</li>
<li><strong>Send a request</strong>: Your code sends text (a “prompt”) to the API</li>
<li><strong>LLM processes</strong>: The model generates a response</li>
<li><strong>Receive response</strong>: You get back generated text</li>
</ol>
<pre><code>Your Code  $\rightarrow$  API Request  $\rightarrow$ LLM Server  $\rightarrow$ Response  $\rightarrow$  Your Code
              (prompt)         (Claude)      (generated text)</code></pre>
<p><strong>Cost</strong>: You pay per token (roughly 1 token <span class="math inline">\(\approx\)</span> 4 characters)</p>
</section>
<section id="the-messages-format" class="slide level2">
<h2>The Messages Format</h2>
<p>LLM APIs use a <strong>messages</strong> structure - a list of conversation turns:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb51"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a></a>messages <span class="op">=</span> [</span>
<span id="cb51-2"><a></a>    {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"Your question or instruction"</span>},</span>
<span id="cb51-3"><a></a>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Each message has:</p>
<ul>
<li><code>role</code>: Who is speaking (<code>"user"</code> = you, <code>"assistant"</code> = the LLM)</li>
<li><code>content</code>: The text of the message</li>
</ul>
<p>You can include multiple messages for multi-turn conversations.</p>
</section>
<section id="setting-up-the-anthropic-client" class="slide level2">
<h2>Setting Up the Anthropic Client</h2>
<p>We are going to show this with Claude, we need an API key</p>
</section>
<section id="setting-up-the-anthropic-client-1" class="slide level2">
<h2>Setting Up the Anthropic Client</h2>
<div id="066e8a76" class="cell" data-execution_count="32">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a></a><span class="im">import</span> anthropic</span>
<span id="cb52-2"><a></a></span>
<span id="cb52-3"><a></a><span class="co"># Initialize client with API key</span></span>
<span id="cb52-4"><a></a><span class="co"># Get your key from: https://console.anthropic.com/</span></span>
<span id="cb52-5"><a></a>client <span class="op">=</span> anthropic.Anthropic(</span>
<span id="cb52-6"><a></a>    api_key<span class="op">=</span><span class="st">"API_KEY"</span> </span>
<span id="cb52-7"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="llm-for-text-summarization" class="slide level2">
<h2>LLM for Text Summarization</h2>
<p><strong>The task</strong>: Give the LLM a long text and ask it to summarize.</p>
<p><strong>Key parameters</strong>:</p>
<ul>
<li><code>model</code>: Which LLM to use</li>
<li><code>max_tokens</code>: Maximum length of response</li>
<li><code>messages</code>: The conversation (our prompt)</li>
</ul>
</section>
<section id="llm-for-text-summarization-1" class="slide level2">
<h2>LLM for Text Summarization</h2>
<div id="06411a0c" class="cell" data-execution_count="33">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb53"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a></a><span class="co"># Get the first chapter text (first 2000 chars for demo)</span></span>
<span id="cb53-2"><a></a>chapter1_text <span class="op">=</span> text_df[<span class="st">'text'</span>].iloc[<span class="dv">0</span>][:<span class="dv">2000</span>]</span>
<span id="cb53-3"><a></a></span>
<span id="cb53-4"><a></a><span class="co"># Call Claude to summarize</span></span>
<span id="cb53-5"><a></a>response <span class="op">=</span> client.messages.create(</span>
<span id="cb53-6"><a></a>    model<span class="op">=</span><span class="st">"claude-sonnet-4-20250514"</span>,</span>
<span id="cb53-7"><a></a>    max_tokens<span class="op">=</span><span class="dv">150</span>,</span>
<span id="cb53-8"><a></a>    messages<span class="op">=</span>[</span>
<span id="cb53-9"><a></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="ss">f"Summarize this text in 2-3 sentences:</span><span class="ch">\n\n</span><span class="sc">{</span>chapter1_text<span class="sc">}</span><span class="ss">"</span>}</span>
<span id="cb53-10"><a></a>    ]</span>
<span id="cb53-11"><a></a>)</span>
<span id="cb53-12"><a></a></span>
<span id="cb53-13"><a></a><span class="co"># Extract text from response object</span></span>
<span id="cb53-14"><a></a>summary <span class="op">=</span> response.content[<span class="dv">0</span>].text</span>
<span id="cb53-15"><a></a><span class="bu">print</span>(<span class="st">"Chapter 1 Summary:"</span>)</span>
<span id="cb53-16"><a></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb53-17"><a></a><span class="bu">print</span>(summary)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chapter 1 Summary:
----------------------------------------
Sir Walter Elliot of Kellynch Hall is a vain baronet who spends his time obsessively reading the Baronetage, a book of aristocratic genealogies, finding particular pleasure in reading about his own family's entry. The text reveals his family details: he was widowed in 1800 and has three daughters - Elizabeth, Anne, and Mary (who married Charles Musgrove in 1810). Sir Walter has personally annotated his family's entry in the book, adding details like his daughter's marriage and the exact date of his wife's death, showing his pride in his aristocratic lineage.</code></pre>
</div>
</div>
</section>
<section id="text-embeddings" class="slide level2">
<h2>Text Embeddings</h2>
<p><strong>What are embeddings?</strong> Numerical vectors that capture semantic meaning.</p>
<pre><code>"The cat sat on the mat"  →  [0.23, -0.45, 0.12, ..., 0.67]  (384 numbers)
"A kitten rested on a rug" →  [0.21, -0.42, 0.15, ..., 0.65]  (similar!)
"Stock prices rose today"  →  [-0.54, 0.33, -0.21, ..., 0.12] (different)</code></pre>
<p><strong>Why?</strong> Similar meanings <span class="math inline">\(\rightarrow\)</span> similar vectors <span class="math inline">\(\rightarrow\)</span> can compute similarity!</p>
</section>
<section id="creating-embeddings" class="slide level2">
<h2>Creating Embeddings</h2>
<p>We use <code>sentence-transformers</code>, a library that runs <strong>locally</strong> (no API needed):</p>
<div id="0097fa75" class="cell" data-execution_count="34">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb56-2"><a></a></span>
<span id="cb56-3"><a></a><span class="co"># load a pre-trained model (downloads once, then cached)</span></span>
<span id="cb56-4"><a></a>model <span class="op">=</span> SentenceTransformer(<span class="st">'all-MiniLM-L6-v2'</span>)</span>
<span id="cb56-5"><a></a></span>
<span id="cb56-6"><a></a><span class="co"># embed first 3 chapters - each becomes a 384-dim vector</span></span>
<span id="cb56-7"><a></a>chapter_texts <span class="op">=</span> text_df[<span class="st">'text'</span>][:<span class="dv">3</span>].tolist()</span>
<span id="cb56-8"><a></a>embeddings <span class="op">=</span> model.encode(chapter_texts)</span>
<span id="cb56-9"><a></a></span>
<span id="cb56-10"><a></a><span class="bu">print</span>(<span class="ss">f"Embedded </span><span class="sc">{</span><span class="bu">len</span>(embeddings)<span class="sc">}</span><span class="ss"> chapters"</span>)</span>
<span id="cb56-11"><a></a><span class="bu">print</span>(<span class="ss">f"Each embedding has </span><span class="sc">{</span><span class="bu">len</span>(embeddings[<span class="dv">0</span>])<span class="sc">}</span><span class="ss"> dimensions"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ec32877f92a24ab99fc0db73991fa686","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Embedded 3 chapters
Each embedding has 384 dimensions</code></pre>
</div>
</div>
</section>
<section id="what-is-cosine-similarity" class="slide level2">
<h2>What is Cosine Similarity?</h2>
<p><strong>Cosine similarity</strong> measures the angle between two vectors, not their magnitude.</p>
<p><span class="math display">\[\text{cosine similarity} = \frac{A \cdot B}{\|A\| \|B\|} = \frac{\sum_{i=1}^{n} A_i B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \sqrt{\sum_{i=1}^{n} B_i^2}}\]</span></p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Value</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>Identical direction (most similar)</td>
</tr>
<tr class="even">
<td>0</td>
<td>Perpendicular (unrelated)</td>
</tr>
<tr class="odd">
<td>-1</td>
<td>Opposite direction (most dissimilar)</td>
</tr>
</tbody>
</table>
<p><strong>Why cosine?</strong> Document length doesn’t matter - a short and long document about the same topic will still be similar.</p>
</section>
<section id="semantic-similarity-with-embeddings" class="slide level2">
<h2>Semantic Similarity with Embeddings</h2>
<p>Once you have embeddings, compute similarity with <strong>cosine similarity</strong>:</p>
<div id="1dd05929" class="cell" data-execution_count="35">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb58"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb58-2"><a></a></span>
<span id="cb58-3"><a></a><span class="co"># Calculate similarity between chapter embeddings</span></span>
<span id="cb58-4"><a></a>similarity_matrix <span class="op">=</span> cosine_similarity(embeddings)</span>
<span id="cb58-5"><a></a></span>
<span id="cb58-6"><a></a><span class="co"># Display as DataFrame</span></span>
<span id="cb58-7"><a></a>sim_df <span class="op">=</span> pd.DataFrame(</span>
<span id="cb58-8"><a></a>    similarity_matrix,</span>
<span id="cb58-9"><a></a>    index<span class="op">=</span>[<span class="st">'Ch 1'</span>, <span class="st">'Ch 2'</span>, <span class="st">'Ch 3'</span>],</span>
<span id="cb58-10"><a></a>    columns<span class="op">=</span>[<span class="st">'Ch 1'</span>, <span class="st">'Ch 2'</span>, <span class="st">'Ch 3'</span>]</span>
<span id="cb58-11"><a></a>)</span>
<span id="cb58-12"><a></a><span class="bu">print</span>(<span class="st">"Chapter Similarity Matrix:"</span>)</span>
<span id="cb58-13"><a></a><span class="bu">print</span>(sim_df.<span class="bu">round</span>(<span class="dv">3</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Chapter Similarity Matrix:
       Ch 1   Ch 2   Ch 3
Ch 1  1.000  0.437  0.393
Ch 2  0.437  1.000  0.553
Ch 3  0.393  0.553  1.000</code></pre>
</div>
</div>
</section>
<section id="visualizing-chapter-similarity" class="slide level2">
<h2>Visualizing Chapter Similarity</h2>
<div id="7f3a3522" class="cell" data-execution_count="36">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb60"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a></a>sim_long <span class="op">=</span> sim_df.reset_index().melt(</span>
<span id="cb60-2"><a></a>    id_vars<span class="op">=</span><span class="st">'index'</span>, var_name<span class="op">=</span><span class="st">'Chapter_Y'</span>, value_name<span class="op">=</span><span class="st">'Similarity'</span></span>
<span id="cb60-3"><a></a>)</span>
<span id="cb60-4"><a></a>sim_long.columns <span class="op">=</span> [<span class="st">'Chapter_X'</span>, <span class="st">'Chapter_Y'</span>, <span class="st">'Similarity'</span>]</span>
<span id="cb60-5"><a></a></span>
<span id="cb60-6"><a></a>sim_long[<span class="st">'label'</span>] <span class="op">=</span> sim_long[<span class="st">'Similarity'</span>].<span class="bu">round</span>(<span class="dv">2</span>)</span>
<span id="cb60-7"><a></a></span>
<span id="cb60-8"><a></a>(ggplot(sim_long, aes(x<span class="op">=</span><span class="st">'Chapter_X'</span>, y<span class="op">=</span><span class="st">'Chapter_Y'</span>, fill<span class="op">=</span><span class="st">'Similarity'</span>))</span>
<span id="cb60-9"><a></a> <span class="op">+</span> geom_tile(color<span class="op">=</span><span class="st">'white'</span>)</span>
<span id="cb60-10"><a></a> <span class="op">+</span> geom_text(aes(label<span class="op">=</span><span class="st">'label'</span>), size<span class="op">=</span><span class="dv">12</span>, format_string<span class="op">=</span><span class="st">'</span><span class="sc">{:.2f}</span><span class="st">'</span>)</span>
<span id="cb60-11"><a></a> <span class="op">+</span> scale_fill_gradient(low<span class="op">=</span><span class="st">'#f7fbff'</span>, high<span class="op">=</span><span class="st">'#08519c'</span>)</span>
<span id="cb60-12"><a></a> <span class="op">+</span> labs(x<span class="op">=</span><span class="st">''</span>, y<span class="op">=</span><span class="st">''</span>, title<span class="op">=</span><span class="st">'Chapter Similarity Heatmap'</span>)</span>
<span id="cb60-13"><a></a> <span class="op">+</span> theme_bw()</span>
<span id="cb60-14"><a></a> <span class="op">+</span> theme(figure_size<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb60-15"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="JSC370-slides-06_files/figure-revealjs/cell-37-output-1.png" class="quarto-figure quarto-figure-center" width="576" height="480"></p>
</figure>
</div>
</div>
</div>
<p>Higher values (darker) = more similar content</p>
</section>
<section id="llm-for-structured-extraction" class="slide level2 scrollable">
<h2>LLM for Structured Extraction</h2>
<p><strong>Powerful capability</strong>: Ask LLMs to return <strong>structured data</strong> (JSON).</p>
<p><strong>How it works</strong>:</p>
<ol type="1">
<li>Give the LLM some text</li>
<li>Ask it to extract specific information</li>
<li>Request output in JSON format</li>
<li>Parse the JSON in Python</li>
</ol>
<p>This lets you convert unstructured text → structured data!</p>
</section>
<section id="llm-for-named-entity-recognition" class="slide level2">
<h2>LLM for Named Entity Recognition</h2>
<div id="db81833e" class="cell" data-execution_count="37">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb61"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a></a><span class="im">import</span> json</span>
<span id="cb61-2"><a></a><span class="im">import</span> re</span>
<span id="cb61-3"><a></a></span>
<span id="cb61-4"><a></a><span class="co"># Use a sample from Chapter 1</span></span>
<span id="cb61-5"><a></a>sample_text <span class="op">=</span> text_df[<span class="st">'text'</span>].iloc[<span class="dv">0</span>][:<span class="dv">1500</span>]</span>
<span id="cb61-6"><a></a></span>
<span id="cb61-7"><a></a><span class="co"># Ask Claude to extract entities and return as JSON</span></span>
<span id="cb61-8"><a></a>response <span class="op">=</span> client.messages.create(</span>
<span id="cb61-9"><a></a>    model<span class="op">=</span><span class="st">"claude-sonnet-4-20250514"</span>,</span>
<span id="cb61-10"><a></a>    max_tokens<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb61-11"><a></a>    messages<span class="op">=</span>[</span>
<span id="cb61-12"><a></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="ss">f"""Extract named entities from this text.</span></span>
<span id="cb61-13"><a></a><span class="ss">Return ONLY valid JSON with keys: persons (list), locations (list), relationships (list).</span></span>
<span id="cb61-14"><a></a></span>
<span id="cb61-15"><a></a><span class="ss">Text: </span><span class="sc">{</span>sample_text<span class="sc">}</span><span class="ss">"""</span>}</span>
<span id="cb61-16"><a></a>    ]</span>
<span id="cb61-17"><a></a>)</span>
<span id="cb61-18"><a></a></span>
<span id="cb61-19"><a></a><span class="co"># Parse JSON from response (strip markdown code blocks if present)</span></span>
<span id="cb61-20"><a></a>text <span class="op">=</span> response.content[<span class="dv">0</span>].text</span>
<span id="cb61-21"><a></a>text <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">^</span><span class="vs">```json</span><span class="dv">\s</span><span class="op">*</span><span class="vs">'</span>, <span class="st">''</span>, text)</span>
<span id="cb61-22"><a></a>text <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">\s</span><span class="op">*</span><span class="vs">```</span><span class="dv">$</span><span class="vs">'</span>, <span class="st">''</span>, text)</span>
<span id="cb61-23"><a></a>entities <span class="op">=</span> json.loads(text)</span>
<span id="cb61-24"><a></a></span>
<span id="cb61-25"><a></a><span class="bu">print</span>(<span class="st">"Extracted Entities from Chapter 1:"</span>)</span>
<span id="cb61-26"><a></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb61-27"><a></a><span class="cf">for</span> key, value <span class="kw">in</span> entities.items():</span>
<span id="cb61-28"><a></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>value<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Extracted Entities from Chapter 1:
----------------------------------------
persons: ['Sir Walter Elliot', 'Walter Elliot', 'Elizabeth', 'James Stevenson', 'Anne', 'Mary', 'Charles', 'Charles Musgrove']
locations: ['Kellynch Hall', 'Somersetshire', 'South Park', 'Gloucester', 'Uppercross', 'Somerset']
relationships: ['Walter Elliot married Elizabeth', 'Elizabeth daughter of James Stevenson', 'Walter Elliot father of Elizabeth', 'Walter Elliot father of Anne', 'Walter Elliot father of Mary', 'Mary married Charles', 'Charles son of Charles Musgrove']</code></pre>
</div>
</div>
</section>
<section id="visualizing-extracted-entities" class="slide level2">
<h2>Visualizing Extracted Entities</h2>
<p>Let’s count the entites by type</p>
<div id="5f2b4389" class="cell" data-execution_count="38">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb63"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a></a>entity_counts <span class="op">=</span> pd.DataFrame({</span>
<span id="cb63-2"><a></a>    <span class="st">'type'</span>: [<span class="st">'Persons'</span>, <span class="st">'Locations'</span>, <span class="st">'Relationships'</span>],</span>
<span id="cb63-3"><a></a>    <span class="st">'count'</span>: [</span>
<span id="cb63-4"><a></a>        <span class="bu">len</span>(entities.get(<span class="st">'persons'</span>, [])),</span>
<span id="cb63-5"><a></a>        <span class="bu">len</span>(entities.get(<span class="st">'locations'</span>, [])),</span>
<span id="cb63-6"><a></a>        <span class="bu">len</span>(entities.get(<span class="st">'relationships'</span>, []))</span>
<span id="cb63-7"><a></a>    ]</span>
<span id="cb63-8"><a></a>})</span>
<span id="cb63-9"><a></a></span>
<span id="cb63-10"><a></a>(ggplot(entity_counts, aes(x<span class="op">=</span><span class="st">'type'</span>, y<span class="op">=</span><span class="st">'count'</span>, fill<span class="op">=</span><span class="st">'type'</span>))</span>
<span id="cb63-11"><a></a> <span class="op">+</span> geom_col(show_legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb63-12"><a></a> <span class="op">+</span> geom_text(aes(label<span class="op">=</span><span class="st">'count'</span>), va<span class="op">=</span><span class="st">'bottom'</span>, size<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb63-13"><a></a> <span class="op">+</span> scale_fill_manual(values<span class="op">=</span>[<span class="st">'#e74c3c'</span>, <span class="st">'#3498db'</span>, <span class="st">'#9b59b6'</span>])</span>
<span id="cb63-14"><a></a> <span class="op">+</span> labs(x<span class="op">=</span><span class="st">''</span>, y<span class="op">=</span><span class="st">'Count'</span>, title<span class="op">=</span><span class="st">'Entities Extracted by LLM'</span>)</span>
<span id="cb63-15"><a></a> <span class="op">+</span> theme_bw()</span>
<span id="cb63-16"><a></a> <span class="op">+</span> theme(figure_size<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb63-17"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="JSC370-slides-06_files/figure-revealjs/cell-39-output-1.png" class="quarto-figure quarto-figure-center" width="576" height="384"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="llm-vs-vader-for-sentiment" class="slide level2">
<h2>LLM vs VADER for Sentiment</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Feature</th>
<th>VADER</th>
<th>LLM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Speed</td>
<td>Very fast</td>
<td>Slower (API call)</td>
</tr>
<tr class="even">
<td>Cost</td>
<td>Free</td>
<td>Pay per token</td>
</tr>
<tr class="odd">
<td>Context</td>
<td>Word-level</td>
<td>Understands context</td>
</tr>
<tr class="even">
<td>Nuance</td>
<td>Limited</td>
<td>Can detect sarcasm, irony</td>
</tr>
<tr class="odd">
<td>Custom output</td>
<td>Fixed scores</td>
<td>Any structure you want</td>
</tr>
</tbody>
</table>
<p><strong>When to use LLMs</strong>: Complex text, need explanations, custom categories</p>
</section>
<section id="llm-for-sentiment-classification" class="slide level2">
<h2>LLM for Sentiment Classification</h2>
<div id="def24e7b" class="cell" data-execution_count="39">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb64"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a></a><span class="co"># Analyze sentiment of a chapter excerpt</span></span>
<span id="cb64-2"><a></a>chapter_excerpt <span class="op">=</span> text_df[<span class="st">'text'</span>].iloc[<span class="dv">5</span>][:<span class="dv">2000</span>]  <span class="co"># Chapter 6</span></span>
<span id="cb64-3"><a></a></span>
<span id="cb64-4"><a></a>response <span class="op">=</span> client.messages.create(</span>
<span id="cb64-5"><a></a>    model<span class="op">=</span><span class="st">"claude-sonnet-4-20250514"</span>,</span>
<span id="cb64-6"><a></a>    max_tokens<span class="op">=</span><span class="dv">300</span>,</span>
<span id="cb64-7"><a></a>    messages<span class="op">=</span>[</span>
<span id="cb64-8"><a></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="ss">f"""Analyze the sentiment and emotions in this text.</span></span>
<span id="cb64-9"><a></a><span class="ss">Return ONLY valid JSON with:</span></span>
<span id="cb64-10"><a></a><span class="ss">- overall_sentiment: positive/negative/neutral/mixed</span></span>
<span id="cb64-11"><a></a><span class="ss">- confidence: 0 to 1</span></span>
<span id="cb64-12"><a></a><span class="ss">- emotions: list of detected emotions</span></span>
<span id="cb64-13"><a></a><span class="ss">- brief_explanation: 1 sentence explaining your analysis</span></span>
<span id="cb64-14"><a></a></span>
<span id="cb64-15"><a></a><span class="ss">Text: </span><span class="sc">{</span>chapter_excerpt<span class="sc">}</span><span class="ss">"""</span>}</span>
<span id="cb64-16"><a></a>    ]</span>
<span id="cb64-17"><a></a>)</span>
<span id="cb64-18"><a></a></span>
<span id="cb64-19"><a></a><span class="co"># Parse JSON (strip markdown code blocks if present)</span></span>
<span id="cb64-20"><a></a>text <span class="op">=</span> response.content[<span class="dv">0</span>].text</span>
<span id="cb64-21"><a></a>text <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">^</span><span class="vs">```json</span><span class="dv">\s</span><span class="op">*</span><span class="vs">'</span>, <span class="st">''</span>, text)</span>
<span id="cb64-22"><a></a>text <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">\s</span><span class="op">*</span><span class="vs">```</span><span class="dv">$</span><span class="vs">'</span>, <span class="st">''</span>, text)</span>
<span id="cb64-23"><a></a>sentiment <span class="op">=</span> json.loads(text)</span>
<span id="cb64-24"><a></a></span>
<span id="cb64-25"><a></a><span class="bu">print</span>(<span class="st">"LLM Sentiment Analysis (Chapter 6):"</span>)</span>
<span id="cb64-26"><a></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb64-27"><a></a><span class="cf">for</span> key, value <span class="kw">in</span> sentiment.items():</span>
<span id="cb64-28"><a></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>key<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>value<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>LLM Sentiment Analysis (Chapter 6):
----------------------------------------
overall_sentiment: mixed
confidence: 0.8
emotions: ['disappointment', 'resignation', 'loneliness', 'gratitude', 'melancholy']
brief_explanation: Anne experiences disappointment and loneliness from the lack of sympathy she receives at Uppercross, but finds some solace in gratitude for Lady Russell's friendship and philosophical acceptance of social differences.</code></pre>
</div>
</div>
</section>
<section id="comparing-vader-vs-llm-sentiment" class="slide level2">
<h2>Comparing VADER vs LLM Sentiment</h2>
<div id="acde969d" class="cell" data-execution_count="40">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb66"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a></a><span class="co"># Get VADER sentiment for first 6 chapters (already computed earlier)</span></span>
<span id="cb66-2"><a></a>vader_scores <span class="op">=</span> chapter_sentiment.head(<span class="dv">6</span>)[[<span class="st">'chapter'</span>, <span class="st">'compound'</span>]].copy()</span>
<span id="cb66-3"><a></a>vader_scores[<span class="st">'method'</span>] <span class="op">=</span> <span class="st">'VADER'</span></span>
<span id="cb66-4"><a></a>vader_scores.columns <span class="op">=</span> [<span class="st">'chapter'</span>, <span class="st">'score'</span>, <span class="st">'method'</span>]</span>
<span id="cb66-5"><a></a></span>
<span id="cb66-6"><a></a><span class="co"># Create comparison data (using VADER scores for visualization)</span></span>
<span id="cb66-7"><a></a><span class="co"># Note: LLM scores would require multiple API calls</span></span>
<span id="cb66-8"><a></a>comparison_df <span class="op">=</span> vader_scores.copy()</span>
<span id="cb66-9"><a></a></span>
<span id="cb66-10"><a></a>(ggplot(comparison_df, aes(x<span class="op">=</span><span class="st">'factor(chapter)'</span>, y<span class="op">=</span><span class="st">'score'</span>, fill<span class="op">=</span><span class="st">'method'</span>))</span>
<span id="cb66-11"><a></a> <span class="op">+</span> geom_col()</span>
<span id="cb66-12"><a></a> <span class="op">+</span> geom_hline(yintercept<span class="op">=</span><span class="dv">0</span>, linetype<span class="op">=</span><span class="st">'dashed'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb66-13"><a></a> <span class="op">+</span> scale_fill_manual(values<span class="op">=</span>[<span class="st">'#2ecc71'</span>])</span>
<span id="cb66-14"><a></a> <span class="op">+</span> labs(x<span class="op">=</span><span class="st">'Chapter'</span>, y<span class="op">=</span><span class="st">'Sentiment Score'</span>,</span>
<span id="cb66-15"><a></a>        title<span class="op">=</span><span class="st">'VADER Sentiment by Chapter'</span>,</span>
<span id="cb66-16"><a></a>        subtitle<span class="op">=</span><span class="st">'Sentence-level aggregation'</span>)</span>
<span id="cb66-17"><a></a> <span class="op">+</span> theme_bw()</span>
<span id="cb66-18"><a></a> <span class="op">+</span> theme(figure_size<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb66-19"><a></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="JSC370-slides-06_files/figure-revealjs/cell-41-output-1.png" class="quarto-figure quarto-figure-center" width="768" height="384"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="local-llms-with-hugging-face" class="slide level2">
<h2>Local LLMs with Hugging Face</h2>
<p>Hugging face is an open-source platform that has a repository with 500,000+ pre-trained models including text models and image models. It is easy to use these models locally.</p>
<div id="e529ae63" class="cell" data-execution_count="41">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb67"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb67-2"><a></a></span>
<span id="cb67-3"><a></a><span class="co"># Load a small sentiment model (runs locally)</span></span>
<span id="cb67-4"><a></a>classifier <span class="op">=</span> pipeline(<span class="st">"sentiment-analysis"</span>,</span>
<span id="cb67-5"><a></a>                       model<span class="op">=</span><span class="st">"distilbert-base-uncased-finetuned-sst-2-english"</span>)</span>
<span id="cb67-6"><a></a></span>
<span id="cb67-7"><a></a><span class="co"># Analyze sentences</span></span>
<span id="cb67-8"><a></a>sample_sentences <span class="op">=</span> [</span>
<span id="cb67-9"><a></a>    <span class="st">"The weather was absolutely delightful."</span>,</span>
<span id="cb67-10"><a></a>    <span class="st">"She felt a deep sense of disappointment."</span>,</span>
<span id="cb67-11"><a></a>    <span class="st">"The meeting was scheduled for Tuesday."</span></span>
<span id="cb67-12"><a></a>]</span>
<span id="cb67-13"><a></a></span>
<span id="cb67-14"><a></a><span class="cf">for</span> sentence <span class="kw">in</span> sample_sentences:</span>
<span id="cb67-15"><a></a>    result <span class="op">=</span> classifier(sentence)[<span class="dv">0</span>]</span>
<span id="cb67-16"><a></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>sentence<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb67-17"><a></a>    <span class="bu">print</span>(<span class="ss">f"  -&gt; </span><span class="sc">{</span>result[<span class="st">'label'</span>]<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>result[<span class="st">'score'</span>]<span class="sc">:.3f}</span><span class="ch">\n</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="combining-traditional-nlp-llms" class="slide level2 scrollable">
<h2>Combining Traditional NLP + LLMs</h2>
<p>Best practices for text analysis:</p>
<ol type="1">
<li><strong>Preprocessing</strong>: Use traditional NLP for cleaning, tokenization</li>
<li><strong>Exploration</strong>: Word frequencies, n-grams, word clouds</li>
<li><strong>Statistical Analysis</strong>: TF-IDF, topic modeling</li>
<li><strong>Deep Understanding</strong>: LLMs for summarization, Q&amp;A, classification</li>
<li><strong>Embeddings</strong>: Semantic search and clustering</li>
</ol>
</section>
<section id="summary" class="slide level2">
<h2>Summary</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Technique</th>
<th>Use Case</th>
<th>Tool</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Tokenization</td>
<td>Text preprocessing</td>
<td>NLTK, spaCy</td>
</tr>
<tr class="even">
<td>Stop Words</td>
<td>Noise removal</td>
<td>NLTK, custom</td>
</tr>
<tr class="odd">
<td>TF-IDF</td>
<td>Important words</td>
<td>scikit-learn</td>
</tr>
<tr class="even">
<td>Sentiment</td>
<td>Opinion mining</td>
<td>VADER, LLMs</td>
</tr>
<tr class="odd">
<td>Topic Modeling</td>
<td>Theme discovery</td>
<td>LDA, NMF</td>
</tr>
<tr class="even">
<td>Embeddings</td>
<td>Semantic search</td>
<td>OpenAI, HuggingFace</td>
</tr>
<tr class="odd">
<td>LLM Generation</td>
<td>Summarization, Q&amp;A</td>
<td>GPT, Claude</td>
</tr>
</tbody>
</table>
</section>
<section id="resources" class="slide level2">
<h2>Resources</h2>
<ul>
<li><a href="https://www.nltk.org/">NLTK Documentation</a></li>
<li><a href="https://spacy.io/">spaCy Documentation</a></li>
<li><a href="https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html">scikit-learn Text Tutorial</a></li>
<li><a href="https://huggingface.co/docs/transformers">Hugging Face Transformers</a></li>
<li><a href="https://docs.anthropic.com/en/docs">Anthropic Claude API Documentation</a></li>
<li><a href="https://docs.anthropic.com/en/api/getting-started">Anthropic API Quickstart</a></li>
<li><a href="https://www.tidytextmining.com/">Text Mining with R</a> (concepts transfer to Python)</li>
</ul>
</section>
<section class="slide level2">



</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script type="application/vnd.jupyter.widget-state+json">
    {"state":{"00fda76fab19428ba27e26da09984100":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26b05eb4b9074c789a8becc9b46ae862","IPY_MODEL_bdf8d626b2e54e6189756b9929a45931","IPY_MODEL_331cf745a77848699821e83fa3256409"],"layout":"IPY_MODEL_a3fe1109b39947c0ba70e44b0961cfc9","tabbable":null,"tooltip":null}},"0b6a0343e3554c1f9be51abb1ea5c115":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_3cb020a13a4246fdbdd79975b7175104","placeholder":"​","style":"IPY_MODEL_638cf0dfdb764478a15f64e9dc2a4b58","tabbable":null,"tooltip":null,"value":" 103/103 [00:00&lt;00:00, 1810.45it/s, Materializing param=pooler.dense.weight]"}},"26b05eb4b9074c789a8becc9b46ae862":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_df032627105d41ecb2e2cbe95833911f","placeholder":"​","style":"IPY_MODEL_79f8ac1562d2410284f6af057056464e","tabbable":null,"tooltip":null,"value":"Loading weights: 100%"}},"2715aaf8d3a34f72beac58e9daf9a42a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_492c0ed02f984979ae6d622b64596e13","placeholder":"​","style":"IPY_MODEL_615c0b18661e4526b144c9f304ad0890","tabbable":null,"tooltip":null,"value":"Loading weights: 100%"}},"309d647abe8e4dd1aa7af30d23a9a000":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"331cf745a77848699821e83fa3256409":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c0c9d827de7349988c13bec4d3b6a473","placeholder":"​","style":"IPY_MODEL_35d036441fa54986aeb084f204026aa8","tabbable":null,"tooltip":null,"value":" 103/103 [00:00&lt;00:00, 1830.98it/s, Materializing param=pooler.dense.weight]"}},"35d036441fa54986aeb084f204026aa8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"38ce116b1d3848c7b51659f9c57fc771":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cb020a13a4246fdbdd79975b7175104":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4768b100480348a0bbf5013b5a4fb677":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"492c0ed02f984979ae6d622b64596e13":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"615c0b18661e4526b144c9f304ad0890":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"638cf0dfdb764478a15f64e9dc2a4b58":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"6c032ea6b59f4ef4941607bb322d136c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_fc3e1166d0cb4351ad32cddc6607f2a7","max":103,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4768b100480348a0bbf5013b5a4fb677","tabbable":null,"tooltip":null,"value":103}},"79f8ac1562d2410284f6af057056464e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a3fe1109b39947c0ba70e44b0961cfc9":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b47418a95a85493988d31d51287d1050":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdf8d626b2e54e6189756b9929a45931":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_b47418a95a85493988d31d51287d1050","max":103,"min":0,"orientation":"horizontal","style":"IPY_MODEL_309d647abe8e4dd1aa7af30d23a9a000","tabbable":null,"tooltip":null,"value":103}},"c0c9d827de7349988c13bec4d3b6a473":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df032627105d41ecb2e2cbe95833911f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec32877f92a24ab99fc0db73991fa686":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2715aaf8d3a34f72beac58e9daf9a42a","IPY_MODEL_6c032ea6b59f4ef4941607bb322d136c","IPY_MODEL_0b6a0343e3554c1f9be51abb1ea5c115"],"layout":"IPY_MODEL_38ce116b1d3848c7b51659f9c57fc771","tabbable":null,"tooltip":null}},"fc3e1166d0cb4351ad32cddc6607f2a7":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>